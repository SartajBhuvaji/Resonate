{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use a demo transcript and store it into Pinecone and retrieve data according to a query.\n",
    "\n",
    "Author: Sartaj, Madhuroopa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Have the `transcript.csv` file in the same directory as this notebook\n",
    "# # Create a .env file with the following variables:\n",
    "# OPENAI_API_KEY\n",
    "# PINECONE_API_KEY\n",
    "# PINECONE_ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "     ---------------------------------------- 0.0/65.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.6/65.6 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/58.3 kB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.14.6-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.7.0-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.7 kB ? eta -:--:--\n",
      "   ------------------------------------- - 215.0/224.7 kB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 215.0/224.7 kB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 224.7/224.7 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/85.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/85.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/85.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/85.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/85.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 81.9/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB 241.2 kB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.9 kB ? eta -:--:--\n",
      "   --------------------------------------  378.9/381.9 kB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  378.9/381.9 kB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 381.9/381.9 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.14.6-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.6/1.9 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.0 pydantic-2.5.3 pydantic-core-2.14.6 sniffio-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.25-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.9 (from langchain)\n",
      "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain)\n",
      "  Downloading langchain_core-0.1.9-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain)\n",
      "  Downloading langsmith-0.0.79-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 225.3/798.0 kB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------ -------------- 491.5/798.0 kB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.0/798.0 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl (364 kB)\n",
      "   ---------------------------------------- 0.0/364.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 364.8/364.8 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.11-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------------------------- - 1.5/1.5 MB 47.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 32.7 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.9-py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 216.5/216.5 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.79-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.4/48.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.25-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.6/2.1 MB 34.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 26.4 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 292.8/292.8 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.4 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 278.1 kB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.7/76.7 kB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tenacity, PyYAML, mypy-extensions, multidict, marshmallow, jsonpointer, greenlet, frozenlist, attrs, yarl, typing-inspect, SQLAlchemy, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community, langchain\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.25 aiohttp-3.9.1 aiosignal-1.3.1 attrs-23.2.0 dataclasses-json-0.6.3 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.0 langchain-community-0.0.11 langchain-core-0.1.9 langsmith-0.0.79 marshmallow-3.20.2 multidict-6.0.4 mypy-extensions-1.0.0 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "pip install langchain  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.2-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.0 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 279.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 202.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Downloading tiktoken-0.5.2-cp311-cp311-win_amd64.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/786.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 317.4/786.4 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  778.2/786.4 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 786.4/786.4 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.5/269.5 kB 8.4 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.12.25 tiktoken-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (6.0.1)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client)\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (4.9.0)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from pinecone-client) (1.26.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru>=0.5.0->pinecone-client)\n",
      "  Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pinecone-client) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\madhu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
      "Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.4 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 61.4/179.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 179.4/179.4 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 300.4/300.4 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.5/62.5 kB 3.3 MB/s eta 0:00:00\n",
      "Installing collected packages: win32-setctime, dnspython, loguru, pinecone-client\n",
      "Successfully installed dnspython-2.4.2 loguru-0.7.2 pinecone-client-2.2.4 win32-setctime-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data and Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>speaker_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>Hello everyone, thanks for joining. Let's disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>I'm excited! Where should we go skiing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>I was thinking of heading to the mountains. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>Speaker 3</td>\n",
       "      <td>That sounds great. What time should we start o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>I suggest we leave early in the morning, aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time speaker_label                                               text\n",
       "0      0.0000     Speaker 1  Hello everyone, thanks for joining. Let's disc...\n",
       "1      0.0025     Speaker 2            I'm excited! Where should we go skiing?\n",
       "2      0.0050     Speaker 1  I was thinking of heading to the mountains. Th...\n",
       "3      0.0075     Speaker 3  That sounds great. What time should we start o...\n",
       "4      0.0100     Speaker 1  I suggest we leave early in the morning, aroun..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "transcript = pd.read_csv('skiing.csv')\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0', 'end_time'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m transcript\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtranscript\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m transcript\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0', 'end_time'] not found in axis\""
     ]
    }
   ],
   "source": [
    "transcript.dropna(inplace=True)\n",
    "transcript.drop(['Unnamed: 0', 'end_time' ], axis=1, inplace=True)\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "to_remove=[]\n",
    "for i, record in transcript.iterrows():\n",
    "    if i < len(transcript)-1:\n",
    "        if transcript.speaker_label[i]== transcript.speaker_label[i+1]:\n",
    "            transcript['text'][i]=transcript['text'][i]+\" \"+transcript['text'][i+1]\n",
    "            to_remove.append(i+1)\n",
    "\n",
    "transcript = transcript.drop(to_remove).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>speaker_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>Hello everyone, thanks for joining. Let's disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>I'm excited! Where should we go skiing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>I was thinking of heading to the mountains. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>Speaker 3</td>\n",
       "      <td>That sounds great. What time should we start o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>I suggest we leave early in the morning, aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time speaker_label                                               text\n",
       "0      0.0000     Speaker 1  Hello everyone, thanks for joining. Let's disc...\n",
       "1      0.0025     Speaker 2            I'm excited! Where should we go skiing?\n",
       "2      0.0050     Speaker 1  I was thinking of heading to the mountains. Th...\n",
       "3      0.0075     Speaker 3  That sounds great. What time should we start o...\n",
       "4      0.0100     Speaker 1  I suggest we leave early in the morning, aroun..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or 'OPENAI_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madhu\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAIEmbeddings instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed.embed_documents(texts)\n",
    "len(res), len(res[0]) # (x,1536) 1536 is the embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_embedding(text):\n",
    "    return embed.embed_documents([text])[0]\n",
    "\n",
    "# get first row of transcript\n",
    "test_embedding_function = create_embedding(transcript.iloc[0]['text'])\n",
    "len(test_embedding_function) # 1 X 1536\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import time\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY') or 'PINECONE_API_KEY'\n",
    "PINECONE_ENVIRONMENT = os.getenv('PINECONE_ENVIRONMENT') or 'PINECONE_ENVIRONMENT'\n",
    "index_name = 'langchain-retrieval-transcript'\n",
    "namespace = 'meeting_topic'\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['langchain-retrieval-transcript']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pinecone.list_indexes())\n",
    "for index in pinecone.list_indexes():\n",
    "    print(pinecone.delete_index(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='euclidean',\n",
    "        dimension=len(res[0])  # model_name = 'text-embedding-ada-002'; 1536 dim of text-embedding-ada-002\n",
    "    )   \n",
    "    \n",
    "while not pinecone.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# index.delete(delete_all=True, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting data into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 23.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_limit = 10\n",
    "texts = []\n",
    "metadatas = []\n",
    "meeting_id = 1\n",
    "\n",
    "for i, record in tqdm(transcript.iterrows()):\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'speaker': record['speaker_label'],\n",
    "        'start_time': round(record['start_time'], 4), # limit to 4 decimal places \n",
    "        'meeting_id': meeting_id,\n",
    "        'text': record['text'], # Storing the text in the metadata for now, later we'd need to decode it from vectors\n",
    "    }\n",
    "\n",
    "    record_texts = record['text']\n",
    "\n",
    "    texts.append(record_texts)\n",
    "    metadatas.append(metadata)\n",
    "\n",
    "    # print(texts)\n",
    "    # print(metadatas)\n",
    "    \n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas), namespace=namespace)\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "        meeting_id += 1\n",
    "\n",
    "# add any remaining texts\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "    \n",
    "time.sleep(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00017,\n",
       " 'namespaces': {'': {'vector_count': 7}, 'meeting_topic': {'vector_count': 10}},\n",
       " 'total_vector_count': 17}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to look up about using LangChain for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '6f08626f-bbdc-42b3-bd7a-af7450eaf6bf',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 1',\n",
      "                           'start_time': 0.0,\n",
      "                           'text': \"Hello everyone, thanks for joining. Let's \"\n",
      "                                   'discuss our skiing plans for this '\n",
      "                                   'weekend.'},\n",
      "              'score': 0.305710793,\n",
      "              'values': []},\n",
      "             {'id': '5d6890eb-e544-4ebf-b151-d321051c669e',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 2',\n",
      "                           'start_time': 0.0025,\n",
      "                           'text': \"I'm excited! Where should we go skiing?\"},\n",
      "              'score': 0.31223309,\n",
      "              'values': []},\n",
      "             {'id': '430e338a-4420-4a2a-b422-80fbc139af09',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 2',\n",
      "                           'start_time': 0.0125,\n",
      "                           'text': \"Perfect! I'll make sure to pack all the \"\n",
      "                                   'necessary gear for skiing.'},\n",
      "              'score': 0.343901634,\n",
      "              'values': []},\n",
      "             {'id': 'c6dc7276-cf0f-4733-aa66-34e51d9c3a4e',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 1',\n",
      "                           'start_time': 0.005,\n",
      "                           'text': 'I was thinking of heading to the '\n",
      "                                   'mountains. The snow conditions there are '\n",
      "                                   'excellent.'},\n",
      "              'score': 0.367274284,\n",
      "              'values': []},\n",
      "             {'id': '3df381d3-e8e0-44c8-b120-a84c75dcb1ac',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 3',\n",
      "                           'start_time': 0.015,\n",
      "                           'text': 'Do we have a plan for transportation? '\n",
      "                                   \"Who's driving?\"},\n",
      "              'score': 0.380061984,\n",
      "              'values': []},\n",
      "             {'id': 'a0535c56-dc4c-4111-b1a0-5c5a3784f797',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 1',\n",
      "                           'start_time': 0.016,\n",
      "                           'text': 'I have a red car that we can use I can '\n",
      "                                   'drive. I have a spacious car that can '\n",
      "                                   'accommodate all of us and our ski '\n",
      "                                   'equipment.'},\n",
      "              'score': 0.418272614,\n",
      "              'values': []},\n",
      "             {'id': '74df4767-0d42-49f3-8c7d-d05a9edeacb4',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 3',\n",
      "                           'start_time': 0.0075,\n",
      "                           'text': 'That sounds great. What time should we '\n",
      "                                   'start our trip?'},\n",
      "              'score': 0.462497592,\n",
      "              'values': []},\n",
      "             {'id': '95fc6fb4-64ab-4d4b-a028-ad72737e0334',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 3',\n",
      "                           'start_time': 0.0225,\n",
      "                           'text': 'What time should we meet at your place?'},\n",
      "              'score': 0.484528065,\n",
      "              'values': []},\n",
      "             {'id': 'bdcd3623-3a10-4b41-9dbf-5a4eb7920e2d',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 1',\n",
      "                           'start_time': 0.01,\n",
      "                           'text': 'I suggest we leave early in the morning, '\n",
      "                                   'around 7 am. This way, we can make the '\n",
      "                                   'most of the day.'},\n",
      "              'score': 0.504442334,\n",
      "              'values': []},\n",
      "             {'id': '993252e6-9a53-407e-a4bf-991f24de0c15',\n",
      "              'metadata': {'meeting_id': 1.0,\n",
      "                           'speaker': 'Speaker 2',\n",
      "                           'start_time': 0.02,\n",
      "                           'text': 'Awesome! Thanks for volunteering to '\n",
      "                                   'drive.'},\n",
      "              'score': 0.54227972,\n",
      "              'values': []}],\n",
      " 'namespace': 'meeting_topic'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "query = \"What was the skiing plan?\"\n",
    "downstr_response = index.query(\n",
    "    vector=embed.embed_documents([query])[0],\n",
    "    namespace=namespace,\n",
    "    top_k=30,\n",
    "    include_metadata=True,\n",
    ")\n",
    "\n",
    "print(downstr_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start_time_up': 0, 'start_time': 0.0, 'start_time_down': 0.03, 'speaker_label': 'Speaker 1', 'text': \"Hello everyone, thanks for joining. Let's discuss our skiing plans for this weekend.\", 'relevant_texts': [\"Hello everyone, thanks for joining. Let's discuss our skiing plans for this weekend.\", \"I'm excited! Where should we go skiing?\"]}, {'start_time_up': 0, 'start_time': 0.0025, 'start_time_down': 0.0325, 'speaker_label': 'Speaker 2', 'text': \"I'm excited! Where should we go skiing?\", 'relevant_texts': [\"I'm excited! Where should we go skiing?\", \"Perfect! I'll make sure to pack all the necessary gear for skiing.\"]}, {'start_time_up': 0, 'start_time': 0.0125, 'start_time_down': 0.042499999999999996, 'speaker_label': 'Speaker 2', 'text': \"Perfect! I'll make sure to pack all the necessary gear for skiing.\", 'relevant_texts': [\"Perfect! I'll make sure to pack all the necessary gear for skiing.\", \"I'm excited! Where should we go skiing?\"]}, {'start_time_up': 0, 'start_time': 0.005, 'start_time_down': 0.034999999999999996, 'speaker_label': 'Speaker 1', 'text': 'I was thinking of heading to the mountains. The snow conditions there are excellent.', 'relevant_texts': ['I was thinking of heading to the mountains. The snow conditions there are excellent.', \"I'm excited! Where should we go skiing?\"]}, {'start_time_up': 0, 'start_time': 0.015, 'start_time_down': 0.045, 'speaker_label': 'Speaker 3', 'text': \"Do we have a plan for transportation? Who's driving?\", 'relevant_texts': [\"Do we have a plan for transportation? Who's driving?\", 'I have a red car that we can use I can drive. I have a spacious car that can accommodate all of us and our ski equipment.']}, {'start_time_up': 0, 'start_time': 0.016, 'start_time_down': 0.046, 'speaker_label': 'Speaker 1', 'text': 'I have a red car that we can use I can drive. I have a spacious car that can accommodate all of us and our ski equipment.', 'relevant_texts': ['I have a red car that we can use I can drive. I have a spacious car that can accommodate all of us and our ski equipment.', \"Perfect! I'll make sure to pack all the necessary gear for skiing.\"]}, {'start_time_up': 0, 'start_time': 0.0075, 'start_time_down': 0.0375, 'speaker_label': 'Speaker 3', 'text': 'That sounds great. What time should we start our trip?', 'relevant_texts': ['That sounds great. What time should we start our trip?', 'What time should we meet at your place?']}, {'start_time_up': 0, 'start_time': 0.0225, 'start_time_down': 0.0525, 'speaker_label': 'Speaker 3', 'text': 'What time should we meet at your place?', 'relevant_texts': ['What time should we meet at your place?', 'That sounds great. What time should we start our trip?']}, {'start_time_up': 0, 'start_time': 0.01, 'start_time_down': 0.04, 'speaker_label': 'Speaker 1', 'text': 'I suggest we leave early in the morning, around 7 am. This way, we can make the most of the day.', 'relevant_texts': ['I suggest we leave early in the morning, around 7 am. This way, we can make the most of the day.', 'That sounds great. What time should we start our trip?']}, {'start_time_up': 0, 'start_time': 0.02, 'start_time_down': 0.05, 'speaker_label': 'Speaker 2', 'text': 'Awesome! Thanks for volunteering to drive.', 'relevant_texts': ['Awesome! Thanks for volunteering to drive.', \"Do we have a plan for transportation? Who's driving?\"]}]\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant information from the metadata\n",
    "results = []\n",
    "for hit in downstr_response[\"matches\"]:\n",
    "    metadata = hit[\"metadata\"]\n",
    "    start_time = metadata[\"start_time\"]\n",
    "    speaker_label = metadata[\"speaker\"]\n",
    "    text = metadata[\"text\"]\n",
    "\n",
    "# Get the text spoken +30 and -30 seconds before and after the identified timestamp\n",
    "    start_time_up = max(0, start_time - 0.03)\n",
    "    start_time_down = start_time + 0.03\n",
    "\n",
    "# Query the Pinecone database to get the relevant text within the specified time window\n",
    "    relevant_texts_response = index.query(\n",
    "        vector = embed.embed_documents([metadata[\"text\"]])[0],\n",
    "        filter={\"start_time\": {\"$gte\": start_time_up, \"$lte\": start_time_down}},\n",
    "        top_k=2,  \n",
    "        namespace=namespace,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    relevant_texts = [hit[\"metadata\"][\"text\"] for hit in relevant_texts_response[\"matches\"]]\n",
    "\n",
    "# Add the relevant information to the results\n",
    "    result = {\n",
    "    \"start_time_up\": start_time_up,\n",
    "    \"start_time\": start_time,\n",
    "    \"start_time_down\": start_time_down,\n",
    "    \"speaker_label\": speaker_label,\n",
    "    \"text\": text,\n",
    "    \"relevant_texts\": relevant_texts,\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.0,\n",
      "        \"start_time_down\": 0.03,\n",
      "        \"speaker_label\": \"Speaker 1\",\n",
      "        \"text\": \"Hello everyone, thanks for joining. Let's discuss our skiing plans for this weekend.\",\n",
      "        \"relevant_texts\": [\n",
      "            \"Hello everyone, thanks for joining. Let's discuss our skiing plans for this weekend.\",\n",
      "            \"I'm excited! Where should we go skiing?\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.0025,\n",
      "        \"start_time_down\": 0.0325,\n",
      "        \"speaker_label\": \"Speaker 2\",\n",
      "        \"text\": \"I'm excited! Where should we go skiing?\",\n",
      "        \"relevant_texts\": [\n",
      "            \"I'm excited! Where should we go skiing?\",\n",
      "            \"Perfect! I'll make sure to pack all the necessary gear for skiing.\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.0125,\n",
      "        \"start_time_down\": 0.042499999999999996,\n",
      "        \"speaker_label\": \"Speaker 2\",\n",
      "        \"text\": \"Perfect! I'll make sure to pack all the necessary gear for skiing.\",\n",
      "        \"relevant_texts\": [\n",
      "            \"Perfect! I'll make sure to pack all the necessary gear for skiing.\",\n",
      "            \"I'm excited! Where should we go skiing?\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.005,\n",
      "        \"start_time_down\": 0.034999999999999996,\n",
      "        \"speaker_label\": \"Speaker 1\",\n",
      "        \"text\": \"I was thinking of heading to the mountains. The snow conditions there are excellent.\",\n",
      "        \"relevant_texts\": [\n",
      "            \"I was thinking of heading to the mountains. The snow conditions there are excellent.\",\n",
      "            \"I'm excited! Where should we go skiing?\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.015,\n",
      "        \"start_time_down\": 0.045,\n",
      "        \"speaker_label\": \"Speaker 3\",\n",
      "        \"text\": \"Do we have a plan for transportation? Who's driving?\",\n",
      "        \"relevant_texts\": [\n",
      "            \"Do we have a plan for transportation? Who's driving?\",\n",
      "            \"I have a red car that we can use I can drive. I have a spacious car that can accommodate all of us and our ski equipment.\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.016,\n",
      "        \"start_time_down\": 0.046,\n",
      "        \"speaker_label\": \"Speaker 1\",\n",
      "        \"text\": \"I have a red car that we can use I can drive. I have a spacious car that can accommodate all of us and our ski equipment.\",\n",
      "        \"relevant_texts\": [\n",
      "            \"I have a red car that we can use I can drive. I have a spacious car that can accommodate all of us and our ski equipment.\",\n",
      "            \"Perfect! I'll make sure to pack all the necessary gear for skiing.\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.0075,\n",
      "        \"start_time_down\": 0.0375,\n",
      "        \"speaker_label\": \"Speaker 3\",\n",
      "        \"text\": \"That sounds great. What time should we start our trip?\",\n",
      "        \"relevant_texts\": [\n",
      "            \"That sounds great. What time should we start our trip?\",\n",
      "            \"What time should we meet at your place?\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.0225,\n",
      "        \"start_time_down\": 0.0525,\n",
      "        \"speaker_label\": \"Speaker 3\",\n",
      "        \"text\": \"What time should we meet at your place?\",\n",
      "        \"relevant_texts\": [\n",
      "            \"What time should we meet at your place?\",\n",
      "            \"That sounds great. What time should we start our trip?\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.01,\n",
      "        \"start_time_down\": 0.04,\n",
      "        \"speaker_label\": \"Speaker 1\",\n",
      "        \"text\": \"I suggest we leave early in the morning, around 7 am. This way, we can make the most of the day.\",\n",
      "        \"relevant_texts\": [\n",
      "            \"I suggest we leave early in the morning, around 7 am. This way, we can make the most of the day.\",\n",
      "            \"That sounds great. What time should we start our trip?\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start_time_up\": 0,\n",
      "        \"start_time\": 0.02,\n",
      "        \"start_time_down\": 0.05,\n",
      "        \"speaker_label\": \"Speaker 2\",\n",
      "        \"text\": \"Awesome! Thanks for volunteering to drive.\",\n",
      "        \"relevant_texts\": [\n",
      "            \"Awesome! Thanks for volunteering to drive.\",\n",
      "            \"Do we have a plan for transportation? Who's driving?\"\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "formatted_results = json.dumps(results, indent=4)\n",
    "\n",
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
