{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS utility functions for Resonate\n",
    "## Video to audio convertor and store the video in firebase\n",
    "# Author: Sartaj and Madhu\n",
    "\n",
    "import boto3\n",
    "import dotenv\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import webvtt\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "def create_client(region_name: str = 'us-east-2') -> boto3.client:\n",
    "    \"\"\"\n",
    "    Create and return an AWS Transcribe client with the specified or default AWS region.\n",
    "\n",
    "    :param region_name: The AWS region where the Transcribe client will be created (default is 'us-east-2').\n",
    "    :type region_name: str\n",
    "    :return: An AWS Transcribe client and an S3 client.\n",
    "    :rtype: boto3.clients\n",
    "    \"\"\"\n",
    "    AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY')\n",
    "    AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id = AWS_ACCESS_KEY,\n",
    "        aws_secret_access_key = AWS_SECRET_ACCESS_KEY,\n",
    "        region_name = region_name\n",
    "        )\n",
    "    return session.client('transcribe'), session.client('s3')\n",
    "\n",
    "\n",
    "\n",
    "def create_s3_bucket(s3: boto3.client, bucket_name: str, region: str = 'us-east-2') -> bool:\n",
    "    \"\"\"\n",
    "    Create an S3 bucket using the provided AWS S3 client if it doesn't exist.\n",
    "\n",
    "    :param s3: The AWS S3 client used to interact with S3 services.\n",
    "    :type s3: boto3.client\n",
    "    :param bucket_name: The name of the S3 bucket.\n",
    "    :type bucket_name: str\n",
    "    :param region: The AWS region where the S3 bucket should be created (default is 'us-east-1').\n",
    "    :type region: str\n",
    "    :return: True if the S3 bucket is successfully created or already exists, else False.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to create the bucket with a specific location constraint\n",
    "        s3.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={'LocationConstraint': region}\n",
    "        )\n",
    "        print(f\"S3 bucket '{bucket_name}' created successfully.\")\n",
    "        return True\n",
    "    except s3.exceptions.BucketAlreadyExists as e:\n",
    "        print(f\"S3 bucket '{bucket_name}' already exists.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating S3 bucket '{bucket_name}': {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def upload_to_s3(s3: boto3.client, file_path: str, bucket_name: str, object_name=None) -> str:\n",
    "    \"\"\"\n",
    "    Upload a file to an S3 bucket using the provided AWS S3 client, and create the bucket if it doesn't exist.\n",
    "\n",
    "    :param s3: The AWS S3 client used to interact with S3 services.\n",
    "    :type s3: boto3.client\n",
    "    :param file_path: The local path of the file to upload.\n",
    "    :type file_path: str\n",
    "    :param bucket_name: The name of the S3 bucket.\n",
    "    :type bucket_name: str\n",
    "    :param object_name: (Optional) The object name in the S3 bucket. If not specified, the file name will be used.\n",
    "    :type object_name: str\n",
    "    :return: The URI of the uploaded file (format: s3://bucket_name/object_name).\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if object_name is None:\n",
    "        object_name = file_path\n",
    "        \n",
    "    try:\n",
    "        object_name = os.path.basename(file_path)\n",
    "        s3.upload_file(file_path, bucket_name, object_name)\n",
    "        uri = f\"s3://{bucket_name}/{object_name}\"\n",
    "        print(f\"File '{file_path}' uploaded successfully to '{uri}'\")\n",
    "        return uri\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file '{file_path}' to '{bucket_name}/{object_name}': {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def download_from_s3(s3: boto3.client, object_name: str, bucket_name: str = 'resonate-output', local_directory: str = '.') -> bool:\n",
    "    \"\"\"\n",
    "    Download a file from an S3 bucket to a local directory.\n",
    "\n",
    "    :param s3: The AWS S3 client used to interact with S3 services.\n",
    "    :type s3: boto3.client\n",
    "    :param object_name: The object name in the S3 bucket.\n",
    "    :type object_name: str\n",
    "    :param bucket_name: The name of the S3 bucket.\n",
    "    :type bucket_name: str\n",
    "    :param local_directory: The local directory where the file should be saved (default is current directory).\n",
    "    :type local_directory: str\n",
    "    :return: True if the file was downloaded successfully, else False.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    local_file_json = f\"{local_directory}/{object_name}.json\"\n",
    "    local_file_vtt = f\"{local_directory}/{object_name}.vtt\"\n",
    "\n",
    "    try:\n",
    "        # Download the file\n",
    "        s3.download_file(bucket_name, object_name + '.json', local_file_json)\n",
    "        s3.download_file(bucket_name, object_name + '.vtt', local_file_vtt)\n",
    "        print(f\"File '{object_name}' (JSON) downloaded successfully to '{local_file_json}'\")\n",
    "        print(f\"File '{object_name}' (VTT) downloaded successfully to '{local_file_vtt}'\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file '{object_name}' from '{bucket_name}': {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def delete_from_s3(s3: boto3.client, bucket_name: str, object_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Delete a file from an S3 bucket using the provided AWS S3 client.\n",
    "\n",
    "    :param s3: The AWS S3 client used to interact with S3 services.\n",
    "    :type s3: boto3.client\n",
    "    :param bucket_name: The name of the S3 bucket.\n",
    "    :type bucket_name: str\n",
    "    :param object_name: The object name in the S3 bucket.\n",
    "    :type object_name: str\n",
    "    :return: True if the file was deleted successfully, else False.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3.delete_object(Bucket=bucket_name, Key=object_name)\n",
    "        print(f\"File '{object_name}' deleted successfully from '{bucket_name}'\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting file '{object_name}' from '{bucket_name}': {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "def delete_s3_bucket(s3, bucket_name):\n",
    "    \"\"\"\n",
    "    Delete an S3 bucket along with its contents using the provided AWS S3 client.\n",
    "\n",
    "    :param s3: The AWS S3 client used to interact with S3 services.\n",
    "    :type s3: boto3.client\n",
    "    :param bucket_name: The name of the S3 bucket.\n",
    "    :type bucket_name: str\n",
    "    :return: True if the S3 bucket and its contents were deleted successfully, else False.\n",
    "    :rtype: bool\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        # List all objects in the bucket\n",
    "        objects = s3.list_objects(Bucket=bucket_name).get('Contents', [])\n",
    "        \n",
    "        # Delete each object in the bucket\n",
    "        for obj in objects:\n",
    "            s3.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "            print(f\"Object '{obj['Key']}' deleted successfully from '{bucket_name}'\")\n",
    "\n",
    "        # Delete the bucket\n",
    "        s3.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"S3 bucket '{bucket_name}' and its contents deleted successfully.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting S3 bucket '{bucket_name}': {e}\")\n",
    "        return False  \n",
    "  \n",
    "\n",
    "\n",
    "def transcribe_audio(transcribe_client: boto3.client, uri: str, output_bucket: str, transcribe_job_name: str='job')-> dict:\n",
    "    \"\"\"\n",
    "    Start a transcription job for audio stored in an S3 bucket using the AWS Transcribe service.\n",
    "\n",
    "    :param s3: The AWS S3 client used to interact with S3 services.\n",
    "    :type s3: boto3.client\n",
    "    :param URI: The URI of the audio file in the S3 bucket.\n",
    "    :type URI: str\n",
    "    :return: The response from the Transcribe service containing information about the transcription job.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    response = transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName = transcribe_job_name,\n",
    "        LanguageCode = 'en-US',\n",
    "        MediaFormat = 'wav',\n",
    "        Settings={\n",
    "            'ShowSpeakerLabels': True,\n",
    "            'MaxSpeakerLabels': 10,\n",
    "            'ChannelIdentification': False,\n",
    "        },  \n",
    "        Media = {\n",
    "            'MediaFileUri': uri\n",
    "        },\n",
    "        Subtitles={\n",
    "            'Formats': ['vtt']\n",
    "        },\n",
    "        OutputBucketName=output_bucket,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_client, s3_client = create_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating S3 bucket 'resonate-input': An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n",
      "False\n",
      "Error creating S3 bucket 'resonate-output': An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(create_s3_bucket(s3_client, 'resonate-input'))\n",
    "print(create_s3_bucket(s3_client, 'resonate-output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:/Users/madhu/Desktop/SeattleUniversity/capstone/resonate_madhu/Resonate/Notebooks/Finance & Corporate Committee - Zoom Meeting.wav/Finance_Corporate_Committee.wav' uploaded successfully to 's3://resonate-input/Finance_Corporate_Committee.wav'\n"
     ]
    }
   ],
   "source": [
    "URI = upload_to_s3(s3_client, 'C:/Users/madhu/Desktop/SeattleUniversity/capstone/resonate_madhu/Resonate/Notebooks/Finance & Corporate Committee - Zoom Meeting.wav/Finance_Corporate_Committee.wav', 'resonate-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://resonate-input/Finance_Corporate_Committee.wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bucket = 'resonate-input'\n",
    "output_bucket = 'resonate-output'  \n",
    "transcribe_job_name = 'Finance_Corporate_Committee'\n",
    "file = 'Finance_Corporate_Committee.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranscriptionJob': {'TranscriptionJobName': 'Finance_Corporate_Committee',\n",
       "  'TranscriptionJobStatus': 'IN_PROGRESS',\n",
       "  'LanguageCode': 'en-US',\n",
       "  'MediaFormat': 'wav',\n",
       "  'Media': {'MediaFileUri': 's3://resonate-input/Finance_Corporate_Committee.wav'},\n",
       "  'StartTime': datetime.datetime(2024, 2, 10, 10, 15, 15, 770000, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2024, 2, 10, 10, 15, 15, 731000, tzinfo=tzlocal()),\n",
       "  'Settings': {'ShowSpeakerLabels': True,\n",
       "   'MaxSpeakerLabels': 10,\n",
       "   'ChannelIdentification': False},\n",
       "  'Subtitles': {'Formats': ['vtt']}},\n",
       " 'ResponseMetadata': {'RequestId': '4dba41db-402f-4519-bbfb-45deca679b9d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4dba41db-402f-4519-bbfb-45deca679b9d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '418',\n",
       "   'date': 'Sat, 10 Feb 2024 18:15:15 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_audio(transcribe_client, URI, output_bucket, transcribe_job_name=transcribe_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Status': 'COMPLETED',\n",
       " 'TranscriptionJobSummaries': [],\n",
       " 'ResponseMetadata': {'RequestId': '5cbd6a97-566d-45f5-8c81-3583347ebc82',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5cbd6a97-566d-45f5-8c81-3583347ebc82',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '53',\n",
       "   'date': 'Thu, 08 Feb 2024 19:51:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_client.list_transcription_jobs(\n",
    "    Status='COMPLETED',\n",
    "    JobNameContains='string',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'Finance_Corporate_Committee' (JSON) downloaded successfully to './Finance_Corporate_Committee.json'\n",
      "File 'Finance_Corporate_Committee' (VTT) downloaded successfully to './Finance_Corporate_Committee.vtt'\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(download_from_s3(s3_client, transcribe_job_name, output_bucket, local_directory='.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4623772e-9967-4990-b636-48d5f90e711a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4623772e-9967-4990-b636-48d5f90e711a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 10 Feb 2024 18:23:22 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_client.delete_transcription_job(\n",
    "    TranscriptionJobName=transcribe_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 'ES2014c.Mix-Headset.wav' deleted successfully from 'resonate-input'\n",
      "Object 'Finance_Corporate_Committee.wav' deleted successfully from 'resonate-input'\n",
      "S3 bucket 'resonate-input' and its contents deleted successfully.\n",
      "True\n",
      "Object '.write_access_check_file.temp' deleted successfully from 'resonate-output'\n",
      "Object 'Finance_Corporate_Committee.json' deleted successfully from 'resonate-output'\n",
      "Object 'Finance_Corporate_Committee.vtt' deleted successfully from 'resonate-output'\n",
      "S3 bucket 'resonate-output' and its contents deleted successfully.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(delete_s3_bucket(s3_client, input_bucket))\n",
    "print(delete_s3_bucket(s3_client, output_bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"Finance_Corporate_Committee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./{file_name}.json', 'r') as f: ## change the file path to the json file saved path that you got from AWS\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract the relevant information from the JSON file\n",
    "segments = data['results']['speaker_labels']['segments']\n",
    "rows = []\n",
    "for segment in segments:\n",
    "        start_time = float(segment['start_time'])/60\n",
    "        end_time = float(segment['end_time'])/60\n",
    "        speaker_label = segment['speaker_label']\n",
    "        rows.append([start_time, end_time, speaker_label])\n",
    "df = pd.DataFrame(rows, columns=['start_time', 'end_time', 'speaker_label'])\n",
    "    \n",
    "    # Load the webvtt file\n",
    "subtitles = webvtt.read(f'./{file_name}.vtt') ## change the file path to the .vtt file saved path that you got from AWS\n",
    "\n",
    "    # Initialize an empty list to store the captions\n",
    "data = []\n",
    "\n",
    "    # Loop through the captions and extract the information\n",
    "\n",
    "for subtitle in subtitles:\n",
    "        start_time = subtitle.start.split(':')\n",
    "        end_time = subtitle.end.split(':')\n",
    "\n",
    "    # Convert start and end time to minutes\n",
    "        start_minutes = int(start_time[0])*60 + int(start_time[1]) + float(start_time[2])/60\n",
    "        end_minutes = int(end_time[0])*60 + int(end_time[1]) + float(end_time[2])/60\n",
    "\n",
    "        text = subtitle.text.strip()\n",
    "\n",
    "    # Append the information to the data list\n",
    "        data.append((start_minutes, end_minutes, text))\n",
    "\n",
    "\n",
    "# Create a pandas dataframe from the data list\n",
    "titles = pd.DataFrame(data, columns=['start_time', 'end_time', 'text'])\n",
    "    # Merge the two tables based on start_time\n",
    "merged = pd.merge_asof(titles.sort_values('start_time'), df.sort_values('start_time'), on='start_time', direction='backward')\n",
    "\n",
    "# Drop rows with NaN values in the speaker_label column\n",
    "merged = merged.dropna(subset=['speaker_label'])\n",
    "\n",
    "# Rename the columns\n",
    "merged = merged[['start_time', 'end_time_x', 'speaker_label', 'text']]  \n",
    "merged.columns = ['start_time', 'end_time', 'speaker_label', 'text']\n",
    "\n",
    "# Reset the index\n",
    "merged = merged.reset_index(drop=True)\n",
    "merged.to_csv(f'./{file_name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video to audio convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in 2023-10-17_New_diffs_architecture_blueprint.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "def video_to_audio(in_path, out_path):\n",
    "    \"\"\"Convert video file to audio file\"\"\"\n",
    "    \n",
    "    video = mp.VideoFileClip(in_path)\n",
    "    video.audio.write_audiofile(out_path)\n",
    "# Video to audio\n",
    "video_to_audio('C:/Users/madhu/Desktop/SeattleUniversity/capstone/resonate_madhu/Resonate/Notebooks/architecture/2023-10-17_New_diffs_architecture_blueprint.mp4', '2023-10-17_New_diffs_architecture_blueprint.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### connect to firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data= {\n",
    "    \"index\": \"langchain-retrieval-transcript\",\n",
    "    \"namespace\": \"new_namespace_1\",\n",
    "    \"last_meeting_no\": 1,\n",
    "    \"last_conversation_no\": 145,\n",
    "    \"unique_meeting_members\": [\n",
    "        \"test2\",\n",
    "        \"test1\"\n",
    "    ],\n",
    "    \"meetings\": [\n",
    "        {\n",
    "            \"meeting_no\": 1,\n",
    "            \"meeting_date\": \"2024-01-24 13:23:38\",\n",
    "            \"meeting_video_file\": True,\n",
    "            \"meeting_members\": [\n",
    "                \"test1\",\n",
    "                \"test2\"\n",
    "            ]\n",
    "            \n",
    "        },\n",
    "       \n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, db, storage\n",
    "def initialize_firebase():\n",
    "    try:\n",
    "        cred = credentials.Certificate(\"resonate.private_key.json\")\n",
    "        firebase_admin.initialize_app(cred, {\n",
    "            'databaseURL': 'https://your-project-id.firebaseio.com',\n",
    "            'storageBucket': 'resonate-917af.appspot.com'\n",
    "        })\n",
    "        print(\"Firebase initialization successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"Firebase initialization failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firebase initialization successful\n",
      "JSON data pushed to '/meeting_metadata' in Realtime Database\n",
      "Video file uploaded to 'Product Marketing Meeting (weekly) 2021-06-28.mp4' in Cloud Storage\n",
      "Your file URL: https://storage.googleapis.com/resonate-917af.appspot.com/Product%20Marketing%20Meeting%20%28weekly%29%202021-06-28.mp4\n",
      "Video file uploaded successfully. Public URL: https://storage.googleapis.com/resonate-917af.appspot.com/Product%20Marketing%20Meeting%20%28weekly%29%202021-06-28.mp4\n"
     ]
    }
   ],
   "source": [
    "from firebase_admin import credentials, initialize_app,db storage\n",
    "\n",
    "def initialize_firebase():\n",
    "    try:\n",
    "        cred = credentials.Certificate(\"resonate.private_key.json\")\n",
    "        initialize_app(cred, {\n",
    "            'databaseURL': 'https://resonate-917af-default-rtdb.firebaseio.com/',\n",
    "            'storageBucket': 'resonate-917af.appspot.com'})\n",
    "        print(\"Firebase initialization successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"Firebase initialization failed: {e}\")\n",
    "def push_json_to_database(json_data, database_path='/'):\n",
    "    try:\n",
    "        ref = db.reference(database_path)\n",
    "        ref.set(json_data)\n",
    "        print(f\"JSON data pushed to '{database_path}' in Realtime Database\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error pushing JSON data to database: {e}\")\n",
    "\n",
    "\n",
    "def upload_video_to_storage(local_path, storage_path):\n",
    "    try:\n",
    "        bucket = storage.bucket()\n",
    "        blob = bucket.blob(storage_path)\n",
    "        blob.upload_from_filename(local_path)\n",
    "\n",
    "        # Opt: if you want to make public access from the URL\n",
    "        blob.make_public()\n",
    "\n",
    "        print(f\"Video file uploaded to '{storage_path}' in Cloud Storage\")\n",
    "        print(\"Your file URL:\", blob.public_url)\n",
    "        return blob.public_url\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading video file to Cloud Storage: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        initialize_firebase()\n",
    "\n",
    "        json_data= {\n",
    "    \"index\": \"langchain-retrieval-transcript\",\n",
    "    \"namespace\": \"new_namespace_1\",\n",
    "    \"last_meeting_no\": 1,\n",
    "    \"last_conversation_no\": 1,\n",
    "    \"unique_meeting_members\": [\n",
    "        \"test2\",\n",
    "        \"test1\"\n",
    "    ],\n",
    "    \"meetings\": [\n",
    "        {\n",
    "            \"meeting_no\": 1,\n",
    "            \"meeting_date\": \"2024-01-24 13:23:38\",\n",
    "            \"meeting_video_file\": True,\n",
    "            \"meeting_members\": [\n",
    "                \"test1\",\n",
    "                \"test2\"\n",
    "            ]\n",
    "            \n",
    "        },\n",
    "       \n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "        database_path = '/meeting_metadata'\n",
    "        push_json_to_database(json_data, database_path)\n",
    "\n",
    "        video_local_path = 'Product Marketing Meeting (weekly) 2021-06-28.mp4'\n",
    "        video_storage_path = 'Product Marketing Meeting (weekly) 2021-06-28.mp4'\n",
    "        uploaded_url = upload_video_to_storage(video_local_path, video_storage_path)\n",
    "\n",
    "        if uploaded_url:\n",
    "            print(f\"Video file uploaded successfully. Public URL: {uploaded_url}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nScript execution interrupted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        firebase_admin.delete_app(firebase_admin.get_app())  # Clean up Firebase app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data pushed to '/' in Realtime Database\n",
      "Error uploading video file to Cloud Storage: Storage bucket name not specified. Specify the bucket name via the \"storageBucket\" option when initializing the App, or specify the bucket name explicitly when calling the storage.bucket() function.\n"
     ]
    }
   ],
   "source": [
    "video_file= 'Product Marketing Meeting (weekly) 2021-06-28.mp4'\n",
    "push_json_to_database(json_data, '/')\n",
    "\n",
    "upload_video_to_storage(video_file, f\"{video_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
