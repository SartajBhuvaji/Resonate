{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use a demo transcript and store it into Pinecone and retrieve data according to a query.\n",
    "- Combined Speaker in Transcript\n",
    "- Uses the new Pinecone Serverless\n",
    "- Doc : https://docs.pinecone.io/docs/new-api\n",
    "\n",
    "Author: Sartaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Have the `transcript.csv` file in the same directory as this notebook\n",
    "# # Create a .env file with the following variables:\n",
    "# OPENAI_API_KEY\n",
    "# PINECONE_SERVERLESS_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pinecone-client #3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data and Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('transcript.csv')\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.dropna(inplace=True)\n",
    "transcript.drop(['Unnamed: 0', 'end_time' ], axis=1, inplace=True)\n",
    "transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining speakers's rows\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "to_remove=[]\n",
    "for i, record in transcript.iterrows():\n",
    "    if i < len(transcript)-1:\n",
    "        if transcript.speaker_label[i]== transcript.speaker_label[i+1]:\n",
    "            transcript['text'][i]=transcript['text'][i]+\" \"+transcript['text'][i+1]\n",
    "            to_remove.append(i+1)\n",
    "\n",
    "transcript = transcript.drop(to_remove).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or 'OPENAI_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed.embed_documents(texts)\n",
    "len(res), len(res[0]) # (x,1536) 1536 is the embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(text):\n",
    "    return embed.embed_documents([text])[0]\n",
    "\n",
    "# get first row of transcript\n",
    "test_embedding_function = create_embedding(transcript.iloc[0]['text'])\n",
    "len(test_embedding_function) # 1 X 1536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_SERVERLESS_API_KEY') or 'PINECONE_SERVERLESS_API_KEY'\n",
    "index_name = 'langchain-retrieval-transcript'\n",
    "namespace = 'new_namespace_2'\n",
    "\n",
    "pinecone = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pinecone.list_indexes())\n",
    "for index in pinecone.list_indexes():\n",
    "    print(pinecone.delete_index(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='cosine',\n",
    "        dimension=len(res[0]),  # model_name = 'text-embedding-ada-002'; 1536 dim of text-embedding-ada-002\n",
    "        \n",
    "        spec=ServerlessSpec(\n",
    "        cloud='aws', \n",
    "        region='us-west-2'\n",
    "        # pod_type=\"p1.x1\",\n",
    "        ) \n",
    "    )   \n",
    "    \n",
    "while not pinecone.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.delete(delete_all=True, namespace=namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting data into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_limit = 90\n",
    "texts = []\n",
    "metadatas = []\n",
    "meeting_id = 1\n",
    "start_id = 0\n",
    "\n",
    "for i, record in tqdm(transcript.iterrows()):\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'speaker': record['speaker_label'],\n",
    "        'start_time': round(record['start_time'], 4), # limit to 4 decimal places \n",
    "        'meeting_id': meeting_id,\n",
    "        'text': record['text'], # Storing the text in the metadata for now, later we'd need to decode it from vectors\n",
    "    }\n",
    "\n",
    "    record_texts = record['text']\n",
    "\n",
    "    texts.append(record_texts)\n",
    "    metadatas.append(metadata)\n",
    "\n",
    "    # print(texts)\n",
    "    # print(metadatas)\n",
    "\n",
    "    # if we've reached the batch limit, then index the batch\n",
    "    if len(texts) >= batch_limit:\n",
    "        #ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        ids = [str(i+1) for i in range(start_id,(start_id + len(texts)))]\n",
    "        start_id += len(texts)\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas), namespace=namespace)\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "        meeting_id += 1\n",
    "\n",
    "# add any remaining texts to the index\n",
    "if len(texts) > 0:\n",
    "    #ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    ids = [str(i+1) for i in range(start_id,(start_id + len(texts)))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "    \n",
    "time.sleep(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to look up about using LangChain for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query  = \"What was talked regarding United States Congress?\"\n",
    "downstr_response = index.query(\n",
    "    vector= embed.embed_documents([query])[0],\n",
    "    # filter={\n",
    "    #     \"meeting_id\": {\"$in\":[1, 2]}\n",
    "    # },\n",
    "    namespace=namespace, \n",
    "    top_k=10,\n",
    "    include_metadata=True,\n",
    ")\n",
    "downstr_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 5\n",
    "id = 60\n",
    "\n",
    "# build a window of size +- delta of all numbers around id\n",
    "window = [str(i) for i in range(id-delta, id+delta+1)]\n",
    "\n",
    "fetch_response = index.fetch(ids=window,namespace=namespace)\n",
    "fetch_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
