,speaker_label,start_time,end_time,text
0,spk_0,0.37165,2.441,"Welcome everyone. Im Shree and Ken. Im a research assistant professor at the Bio Complexity Institute. Im really excited to be the moderator for the session. The ongoing COVID19 pandemic has appended lives across the world. It has also integrated the global scientific community to join forces and make significant strides in fundamental research, technology development and real time support. As we embark on this third year of this pandemic, it is a useful time to reflect upon the road travel so far and what it means for the future of pandemic science and preparedness to discuss this topic with us. We have three eminent experts in scientific operational and technological aspects. Doctor Eli Klein Justin Crow and Doctor Li Jian. Welcome everyone to the panel. Just before we get started. Ill give a brief idea of the panel format. Well begin with initial remarks from each of the panelists. Following that, well have a specific set of questions on the panic response so far, the second part will focus on the path forward and whats next for epidemiology. Well also have time for audience questions at the end of each part. So further ado Ill invite our first Panelist to give their initial remarks. Doctor Elly Klein is an Associate professor, the Department of Emergency Medicine at Johns Hopkins University. Upon finishing his phd in Ecology and evolutionary Biology from Princeton University. Doctor Klein joined the Johns Hopkins faculty in 2012. He is also a senior fellow at the Center for Disease Dynamics Economics and Policy in Washington DC. His research focuses on the role of individuals in the spread of infectious diseases, an area that sits at the nexus of economics and epidemiology. The primary disease focus of Doctor Kleins research is antimicrobial resistance and the spread of disease within the hospital. Hes actively involved in research efforts supported by the Centers for disease control and prevention as well as Agency for healthcare research and quality. Welcome, Doctor Klein on to you for your initial remarks."
1,spk_1,2.46215,6.852833333333333,"Thank you so much, everyone for being here and uh very exciting to be at this event. Well, sort of be at this event. Sorry, I cant actually be there in person, but I think its very timely at at least somewhat as we move into the starting to move into this post pandemic phase to sort of begin the process of looking back. I mean, I think this is an exciting time period, uh start evaluating how things are doing, especially as it looks like another pandemic is starting and as we all start to gear up to look at monkeypox. But you know, I I think given sort of the historical background. Theres a lot of things that weve learned over the last couple of years. I know theres a lot of questions that were gonna be talking about within that context. But, you know, my research has been on mathematical modeling and, and antimicrobial resistance and infectious disease the last couple of years prior to COVID. And the transition to COVID meant for all of us devising new models or repurposing old models and trying to understand the context of how all of these things fit together and what was the most appropriate for public policy and, and for the audiences that we were trying to address. And, and I think the resulting impact of all of this is, is what weve seen is that theres been a tremendous amount of effort now to both improve how the models work and the ability of those models to provide some utility, but also to drive important connections across the system. And whether that is grants that are specifically related to trying to improve ties between the academic researchers and, and public health departments or whether its sort of broader national goals of, of building these networks of forecasting all the forecasting models or the scenario modeling hubs, all of these things to bridge these groups together and try to find ways in which to communicate the policies and communicate the science in a way that can provide some input in the public policy. And I think as weve seen over the last several years is politicians have chosen when its convenient to follow and listen to the models and when it has not been convenient, they may have not followed them. And its unfortunate in some to see the science politicized. But I think partly where we can sort of go with this and thinking about these things, how to take these meetings and events and formalize them in a way that can make it more of a standard in terms of how these things are communicated. So that when people look at information, its not novel, its not new in the same way that it has been and, and the way that weve been asked in many ways to think about it is to think about it in the terms and the way weather forecasting has worked, right? And I think theres a lot of misleading aspects to that parallel. And most importantly being that uh when you make a weather forecast, that doesnt change the weather forecast, whereas if you make a disease prediction, that could actually change how that prediction plays out, obviously, that thats a major issue in terms of thinking about it. But when we think about the history of weather forecasting over the last 50 or 70 years, it has been a tremendously large investment over the span of seven years to the point where we are now, you know, the first stuff involved radar balloons and now we have satellites, right? And then the launch of a satellite costs something like $60 million for each satellite. And theres several weather satellites and they launch a new one every couple of years and theyre touting the fact that we put 25 million into potentially forecasting in one year. So, I mean, I think that theres a lot of infrastructure that still needs to be built and theres a lot of sort of basic work that goes into building weather forecasts that we dont sort of have that built in infrastructure, not that I, I think we should get to the same level and there are different policy outcomes, the weather forecasting. I think in terms of how people thought about it, thats what theyve thought about. And so from that end, I think we need a lot more money to sort of formalize a lot of things, these things. On the other hand, I think we also need to start reframing how modeling can be useful in informing public policy. And I think thats sort of the like broader context in which I I Ill try to stay within my time frame."
2,spk_0,6.863816666666667,8.228666666666667,"Thats really helpful and it sets the context for the discussion because were right at this nexus point where we can look backwards, but we still have some memory that we can carry forward so that we dont re invent the wheel every time. So without going further, Ill go ahead to the next Panelist for their initial remarks Justin Crow, I I mean, I got to know him remotely like uh two years back and only last week we met in person for the first time. So Justin K is the Director of Division of Social Epidemiology Office of Health Equity at the Virginia Department of Health, where his role is to provide strategic and operational leadership of research, analysis and presentation to ensure methodological and data quality and to collaborate with stakeholders to identify needs. Recently, he started in his new role as foresight and analytics coordinator at the Virginia Department of Health Office of Emergency Preparedness. His task there involves better connection of forecasting early warning systems and modeling to policy decisions, program design and preparedness planning. He has a masters in public administration from the Virginia Commonwealth University and a BLS in Political Science from University of Mary Washington. He is also a certified super forecaster with the good Judgment project where he provides pro forecasts of political and economic events for diverse group of plants. Welcome Justin and on to you."
3,spk_2,8.244833333333334,13.448166666666667,"Great. Thank you Srini. And yeah, its been great working with you and your team at the Bio Complexity Institute for the past two years. Its been a trying time, but Ive learned a lot working with you all. Yeah, Srini mentioned my background here. Im not an academic, I dont have really much training in epidemiology or you know, statistical methods or modeling here. Uh My background is in public administration. Uh I did study policy analysis but I got my start really in regulatory analysis, looking at regulation of health professionals. And I ended up in in health and social epidemiology really due to my background and understanding of uh social, demographic and economic data sets and also the health workforce realm. So I do have, you know, during my studies, I did take some modeling, some data, some analysis, really geographic information systems classes. But while I was working as a regulatory alys, as you mentioned, I did get involved with the Good Judgment project, which is an aggregate human forecasting tournament. They forecast geopolitical events and you know, our role was just to go in and, and kind of analyze those events. I think about it pretty thoroughly and try to understand what was going on with those events and give a a probability that an event would occur or not occur or you know, different outcomes that they would look at. So again, not really formal training, that was a hobby, but I did get some training and some experiences thinking about the future and how forecasting would work. And that was enough of a background as Renee mentioned for me to when the pandemic hit to be assigned to coordinate the the forecasting and modeling work that really U VA was doing and they hit the ground running. I dont know if you all remember, Im sure you do at the beginning of the pandemic when uh it was first affecting uh Wuhan China. They were throwing up huge hospitals in 10 days to treat so many patients. Of course, uh Italys health system was getting overwhelmed, were doing emergency triage at the time, right? When cases were beginning to explode in New York and uh we were sending the US s comfort up there and starting to throw up our own field hospitals around the country here in Virginia. Though we were able to, we started to throw up this, you know, put up those field hospitals. But we were able to pause that largely because the U VA Bio Complexity Institute and their models were showing that the measures being taken, the public health emergency uh measures were were being effective and they were flattening the curve here in Virginia. So we were able to pause those field hospitals, save ourselves or save really in the end FAA great deal of money. But for us, a staff of V DH uh save staff time and resources at a very, very trying and stressful time. So that work was essential to get us really started with uh whats been overall, a pretty successful response to the pandemic. Virginia is number 10 in age adjusted death for COVID throughout the pandemic. And uh prior to the pandemic, we were we ranked 17th in that rank. So for response to COVID, I think that says a lot, one of the things I like about forecasting and working with the modeling team here is that you do really need to know everything that you can about any situation or protect the future. So whether youre doing quantitative modeling and, and you have uh a novel convert virus, you need to know as much as you can about that virus and whats going on and how people are reacting to try to understand whats going on in the future and develop a different scenarios for your model. Uh The same is true for, for a human forecast, youre putting a probability on say, you know whether a mass mandate will be put in place or lifted, you need to know everything you can about the number of cases, the policies and the political. So youre bringing in a lot of different data and information systems. So with the U VA team, of course, they had a voracious appetite for data and we were, we were very eager to supply at the beginning, but we really immediately saw issues. Uh right at the beginning of the pandemic, the public health emergency helped us. It helped us kind of vent some of our, our rules. But uh we had difficulty getting really data sharing agreements in place. We had difficulties with data integration, uh interoperability of the data, bringing it all together and getting really the U VA team and users uh up to speed on what data was available, what the limitations were and how it was collected. Uh So that they could really understand how to use it. So Im excited to uh at this point, you know, look back at lessons learned, we talked about the need to do a postmortem for the modeling specifically, really understanding how to get those systems in place and, and keep them in place for the next pandemic. Should it come? Hopefully, uh its not monkey pots, but were still keeping a very close eye on that and to really understand how we can link modeling, forecasting these data streams to decisions. As I said, its not always as well linked as wed like. Sometimes we put those forecasting projections out there and people arent quite sure what to do with them, particularly when there are scenarios and using it for policy analysis. So one of the things I hope to do in my new position and Im Im glad that Virginia has made a commitment to that role and that work is to data streams and these projections to policy decisions."
4,spk_0,13.471483333333333,14.8855,"Thank you, Justin. And I see mother and Brian are there in the main room. I I think they can attest to the fact that youve been a champion in terms of taking our models and taking it to the right divisions, but also going to the divisions and getting their problems and bringing it back to us and navigating the data landscape has been challenging right from day one, even till date, like trying to figure out whether this data works with that on the modeling front, but also whether the same license agreement works, do you need to reach out to a different person? And I think thats been a big challenge and I think thats something that well talk about in the next part. So on the next analyst, Dr Li Xiang is a professor of Computer Science and biomedical informatics at Emory University. She held a Winship, distinguished professorship from 2015 to 2018. She has a phd from Georgia Institute of Technology and MS from Johns Hopkins University and a BS from University of Science and Technology of China. She and a research lab conduct research on algorithms and methods at the intersection of data management, machine learning and data privacy and security with a recent focus on privacy, preserving and reverse machine learning. Her research is supported by federal agencies including Nsfnihaf, OS R Porry and Industry Awards including Google IBM Cisco to name a few. She is an I AAA fellow and an AC M distinguished member. Welcome, Doctor Li Jian on to you."
5,spk_3,14.897,20.511816666666668,"So thank you. She thank you everyone for inviting me. Its a great pleasure for me to be here. I had the pleasure and fortune to work with Mado and the entire team for the virtual organization, prepare for computing. Researchers work on pandemic research thats sponsored by NSF. So I learned a lot from the team in general. So my lab, we are not a epidemiology or as she mentioned, my background is mainly computer science and in particular on data privacy and robust machine learning. So my lab is basically working on intersection of data management, machine learning and information security and we work on particularly for health applications and location based applications and of course public health applications. So this pandemic research really is a great opportunity for us to use. For example, like mobility data, utilize our expertise in these areas, try to come up with solutions to help on public health research. So we have had the opportunity to work on two projects related to pandemic research. The first one is a project funded by the NSF Rapid Program where we try to develop a real time contact tracing and risk monitoring system via privacy enhanced mobile tracking. So this project ended recently and the goal uh as we can see here now is this is really a very familiar concept. We wanted to have users submit their locations so that we can use the locations to figure out to do contact tracing, to try to based on where the users visit and who the users have contact with. Then we can figure out the risk of each individual users. And one of the main component of our project is to enhance the privacy because the raw locations can be privacy sensitive. And in order to enhance privacy, our main research is to see how users can actually control and uh refine the precision of the location in order to share the location to the server, so that the server can use the location to do the contact tracing and the risk monitoring. And we are using a statistical privacy notion. And some of you might be familiar with, its called geo indistinguishable, which is really a generalized variant of the differential privacy, which is more commonly known. This is a generalization of the differential privacy notion in the geospatial domain. And essentially you can think of it as just a perturbation mechanism. If the user have a true location, we can actually perturb the location on the device using some privacy parameter. And you can see on the left hand side, these are based on different privacy parameters. If you have the true location, the blue dot then you can actually draw a random sample from the distribution like one of the red dots would be the perturbed location of that user. So the higher the privacy protection you can see the more spread out the randomized distribution. So the more likely the perturbed location may be further away from the true location, right. So the challenge would be given these perturbed locations that are submitted to the server. How can we still figure out with some good precision or accuracy that the two user is still in contact? And because the most important thing for contact tracing is to see whether two users are in contact or not. So we did some modeling basically there some statistical algorithm development and so on. And we basically showed its still feasible. Its possible to do this kind of contact tracing with this privacy protection. Its basically a trade off between privacy protection and the contact tracing utility. And in terms of techniques, we have some techniques that demonstrates the effectiveness and so on. But I would have to say this project is in terms of the practical deployment point of view, its really considered a failure because we promised to actually deploy some app right for the users to use. But it just turned out the administrative overhead in terms of getting the security review for the mobile apps and getting the IRB review and all of those takes so much longer than we expected. So by the time we are ready to roll out, essentially, the timing is just passed, it just doesnt make sense to do contact tracing anymore. So this project just ended, we have some good techniques, some good papers come out of it, but really not really a good deployment or any practical um impact. And then right now, we are starting a new project on hyperlocal risk monitoring and pandemic preparedness through privacy enhanced mobility and social interactions analysis. So this one instead of doing the individual risk monitoring, were really interested in doing community or location based risk monitoring, basically figure out what is the infection risk of a particular hyperlocal region. And one of the interesting thing we want to do in this project. It is a collaboration with Japan. So we want to study different mobility patterns, different socio economical factors, cultural factors, how they actually impact the disease spread and how they impact risk based on the mobility data. And of course, we want to also understand the social factors that impact the risks. For example, people in rural area versus in more poor areas, how their mobility pattern actually changes and how they actually react to these different risk factors and so on. So these are in collaboration with our social science collaborators. And of course, on the bottom, we want to also build a privacy enhanced data collection aggregation so that we can enable privacy while still collecting and use different kinds of data including mobility data and social interaction data to enable these kinds of analysis. So I think these are the main context I have. So I think Shrini has some questions and the remarks I will make probably mainly gonna be drawn from the context that Im familiar with in terms of data access, data sharing and responsible use of the data, data privacy and so on. So I look forward to also listening to other panelists in terms of the communication policy and operation aspects. Thank you."
6,spk_0,20.52465,20.96015,"Thank you, Lee. I I think you nicely segued into the first question that I had to. We were debating like brand and I were debating whether we should frame it in a positive sense or negative. So the question was, what are some of the biggest obstacles you faced during the COVID19 response? And whether any success stories, I think you brought up one of the challenges that you had, but maybe Ill start with you and then we can go to the other panelists. Do you want to expand on some of the other obstacles or how would they overcome?"
7,spk_3,20.9675,23.255983333333333,"Sure. Sure. Yeah. So I think one of the obstacles I mentioned is the administrative um aspect or burden which really I dont have any solution for. But the other major obstacles we have encountered during our projects, I would say is the access to the data and this is not limited to the access to that raw data, but it is also the access or the availability of fine grained or multimodal data that are actually aligned. So I think thats one of the major challenges I can give you some examples. So for example, we were trying to study the mobility data and their impact on the disease spread. So we actually have access to a real world mobility data through a company called VR set through one of our collaborators. So these are actually real fine grained raw mobility data. However, we dont have the matching case data or we dont have the matching mobility data in other countries like Japan if we want to do like comparative studies. So I think these are some of the challenges that we counter and our social scientists, for example, they can use the survey data, the US long term survey data to study some of the social factors in the US. However, we dont really have a aligned data from other countries. Either they may have some other surveys in Japan, but they do not align in terms of time or the set of questions they ask the users or the participants. So again, this just uh created some challenges. And one of the nice thing is a lot of these service providers like Facebook and Google, they did release some of the data. However, they are in this aggregated form, an anonymized form. So again, theres alignment issues, theres this fine grain or granularity issues. So I think these are the major obstacles that we encounter and some of the temporary solutions or solutions would be we use simulated data for some of our studies that we published. And were also trying to actually uh reaching out to ma and the team, I know the U VA team has a great set of simulated data that I think would really benefit a lot of the study teams or research teams that have the multimodal, very fine grain data from multiple aspects. So I think that is a really nice direction I think to enable some of the data driven research."
8,spk_0,23.286483333333333,23.71815,"OK. So if I understand correctly, there is on one side, there is challenge in aligning these multi model data because theyre coming from different providers, but also theyre coming at different time snapshots. So data collection process theyre collected for totally different purposes. So its difficult to align them post facto. And uh I really like that you highlighted another use case of models as the coordinate system for bringing these together in some sense."
9,spk_3,23.73065,24.55815,"Exactly. Yeah. Yeah, there are some success stories as I mentioned that this differential privacy is being used by the mobile service companies to release their data, but they are in aggregated and anonymized form. So the use of it might be limited and again, it creates challenges to align with other data, right to to link with other data. And then for example, federal learning is also a I think a successful story that would allow multiple data centers or health institutions to answer COVID related questions for example. But most of these I I would say is limited to the horizontal setting where all the features are the same and so on, right? But if we have different providers who have different aspects of data, like user survey data, user behavior data and then the health records and then the mobility data, how do we link them together? Its really a challenge"
10,spk_0,24.5815,24.8525,"and I know from uh working with Anna and brand like I think Doctor Klein, you work with a lot of hospital acquired infection related data which is at level and maybe you also face similar challenges maybe do you wanna expand upon other similar obstacles that you face during the COVID response?"
11,spk_1,24.8735,29.040816666666668,"Sure, I I think obviously the connectivity and and the data process was an enormous challenge, right? And I think that that theres several dimensions to it. I I think, you know, obviously one aspect is being able to link mobility data with case data, right? And and they come in different formats that came from different places. I I think part of it is also there was no infrastructure for doing most of this stuff and much of it is like gated in in private. And so certain researchers would get access to this mobility data. Researchers would get access to this other mobility research data set and they may or may not show the same information. And so I think that was always this problem of like how to integrate all this these different types of data, which was not a problem we typically had before COVID where everyone was scrambling to get any sort of data, right? And and I remember it was probably 10 years ago, maybe more than that, somebody had built like a very simple app where they were able to track like a couple 100 users who like downloaded the app and the people agreed to do it so they could see how people actually move. And I remember thinking, wow, this would be amazing if we could have this sort of type of data for like flu, that we could see how many people moved around and all this stuff and we could see how flu spread. And now we basically had that and, and it didnt really seem to actually be that useful in many cases. And I, I think partly, you know, the problem with some of this data beyond the fact of like, how do you get access to it? How do you correlate it is that its crude cell phone movement data doesnt tell you anything about what the person is doing or where they are. So you can imagine two people being very near each other but having no contact or maybe theyre in the same place, but theyre both wearing masks, none of thats counted and none of thats brought into the model. So you have to either have a data from elsewhere, you have to pull in other things. And I I think thats one of those challenges of how did, how do we deal with all of this? Suddenly this plethora of data that we had and to be fair to all these companies, you know, these were private companies, they had the data model, whether you agree with their privacy implications of it or not. That was like the model that they had and they were building stuff around that. And then suddenly many of them gave it away for free to researchers in the hopes of helping this stuff, right? And now obviously most of it is that free dumps of data have suddenly disappeared again. Right. So the ability to sort of think through how to move forward in terms of how to use that data and process that the best way and build it into pipelines that can be useful in the next pandemic arent or even seasonal epidemics just arent there now. Right. And so some people might have some special access and they have special DUAS, but its not sort of like this widely available thing that is useful for many people. Right. So I think thats sort of sort of major obstacle and challenge in terms of that data. Its like not just the transmission and the processing of it, but sort of like how do we build these pipelines to be able to handle this data in the event of a future issue? And then, you know, obviously the other part on top of that is how do you process these enormous amounts of data? So you have pro processing of these enormous OS data and then running these models. And I know the Bio Complexity Institute has like a big huge setup and built all of these stuff that, that was already there to be able to run these models, but maybe not everybody had that. So for instance, we would scale things up and down a little bit on, on AWS, but that was quite expensive. And there was, Im forgetting the name of the group, the Illinois. Group champagne. They, they have that uh giant set of servers out there that they actually left. Im pretty sure the government paid for it somehow, but they were letting us use them for free. And then the army actually, we worked with them and they actually were running some of our models on their servers. So getting access to sort of these like big computational servers on like a very rapid basis was, was certainly a challenge in terms of building some of these bigger models and having them able to run and scaling them up quickly, which is, you know, we hadnt had to do in any sort of way."
12,spk_0,29.0755,29.525666666666666,"So data as well as computing and also the the dental infrastructure to take it from data to the computing systems and so on. I think theyre pretty much in the span of the size which is supporting this expeditions sometimes. Like I think a lot of the discussion that we have had in the past workshops and also in some of the discussion groups hint towards these challenges, like how do we codify them, Justin, do you want to add something on this topic before we go to the next question?"
13,spk_2,29.5625,32.52183333333333,"Yeah, definitely. And I think I definitely have a different angle on it, but kind of the same issue working for the state, really, a lot of our data systems are really siloed. So our funding for our data systems tends to be grant based and grants tend to be uh very specific in what they try to do. So we might have a grant for providing vaccines. We have a separate grant for surveillance and cases, another one for uh outbreak investigations and those grants tend to be very silent. So the the data systems have been built around those specific functions. So they dont always collect data in the same way. The data isnt generally always interoperable and theyre not really linked and theyre also, you know, built for a much smaller scale than we had to do during the pandemic. So we had to ramp up really quickly these data systems that, that dont really talk to each other very well. And, and theyre built really for a much smaller scale. Youre talking maybe hundreds of cases and not tens of thousands at a time. So try to bring a lot of people on board who are also siloed in their training and theyre working with, with systems. So that was a very difficult thing to do. Were also trying to get data from hospitals, health care providers, laboratories that are also getting swamped with work and, and data requirements. So a lot of the data systems that we had in place, the fields werent getting filled in, all the fields werent getting filled in it. At first. Its, its, its definitely understandable. Um We had to, you know, work pretty hard to get our hospitals and health systems. They were, they were very cooper, you know, essential during the pandemic. Uh but they were getting swamped as well. So trying to worry about collecting the data that they needed was difficult and a lot of that data is proprietary and we work through our Virginia Hospital and health care associate. So its a little like herding cats to get permission to share that data during a busy time period. So getting all those data systems built up, getting collection instruments built up, getting the people who are using those systems to fill out all the fields. In some, some cases, we eventually just made them required. You couldnt submit, say your test report without filling and race and ethnicity. But we had to build up to that and have policy changes and really analysis and understanding of what was going on in order to get there. So, you know, and I think one of the other things that we struggled with early on with something weve talked about is is data privacy. So our inclination is to really uh protect that that private health information during a public. And one of the one of the ways we do that is to not share data with everyone, you know, to keep it uh separate. So at a time when you really need to ramp up your analysis and work with partners like the U VA Bio Complexity Institute, kind of breaking down that culture and and understanding how to do it while protecting ph I but meeting the needs of this new emergency. I think that was something a challenge that we face very early in the pandemic."
14,spk_0,32.559,33.518316666666664,"So its interesting that you highlight the data collection process because I think while smartphones and other sensors allow us to do passive data collection at scale. A lot of these systems are at like hospitals or clinics where people are getting diagnosed. There, there is a human element to this data collection. So asking them to fill out multiple fields, requires a human to go through that. And theres a, theres a lot of the question on whether these systems will stay or how, how will they evolve after the phes expire? So, so thats a very valuable thing to keep in mind as modelers and also as people who consume the data, we need to really see whether a particular data collection system is giving us the required benefit and try to downscale it. Keeping in mind the human cost and the infrastructure costs in mind. So we have like maybe 5, 10 minutes before we jump into the next session. I wanna open it up for audience if they have any questions in the main room or others on zoom."
15,spk_4,33.550666666666665,34.0795,"All right. So um Justin, I was thinking about what you said for this question, but everyone could chime in I I in our breakout group, we were thinking about what, what was the advantage of modeling or how did you learn to trust it or trust these nuts from bio complexity. We were there things that you wished the modelers had known going in or how, how did that work? And what might you change in terms of the perspective of us modelers? Like, what should we be thinking about next time this happens and have to work with someone like you or decision makers."
16,spk_2,34.11848333333333,35.468983333333334,"Yeah. Well, I think from the onset they were very clear about what the projections were, that they werent predictions and thats immediately what any person whos not familiar with the forecast thinks its, its a prediction, its a crystal ball. Were trying to tell you exactly whats going to happen, the exact number of cases and when theyre going to peak. So, so I think the U VA team was great at really, uh you know, stating that these are projections, we cant tell you exactly what the level is going to be when its going to peak and explaining the different scenarios and what they meant. And really what they did was they really gave it an inaction thing, you know. So with, at the field hospital, as I mentioned before, what they ended up saying was, you know, we can give you six weeks notice if you need to set up a field hospital. So they werent overstating what they could do, but they were stating really what the state could do with the information that uh U VA was able to provide if that makes sense. So they were really providing something actionable and something that the governor could hang his hat on or the governor or his team, her COVID leadership team could hang their hat on as supporting that decision and allowing the team to take a, a definite action. So I think those two things to combine, not overstating and then giving something concrete to do and what that information can let you do is very helpful. All right, thanks."
17,spk_1,35.4885,37.85916666666667,"I think one of the other things that we have as an issue around that same idea is is sort of the question of scale versus risk, right? And so just when youre talking about how far in the future, you could maybe look to say, well, maybe this is when we might need something. And thats sort of at the state level, like I spent some of my time or a lot of significant working with the specific hospital and the questions there were much more localized. So there wasnt as much at the state level, but at the like more local Baltimore level and how, how would things play out there versus at the country level? And I, I think one of the things that we have this problem with in terms of modeling is the models can be actually pretty good at sort of an aggregate because theyre regression to the mean, youre looking at large numbers and you have this, the SAR models then start to look pretty good when you aggregate to the, you know, the state or even the national level. But when you start looking at these local levels, you get all these little peaks and curves and a lot of randomness. And how do you use that at a like local level to assess risk for a hospital or assess risk for a county or, and, and I think one of the other big challenges is that a lot of these case numbers that were reported and all that stuff again were aggregated to some extent. And those aggregations may or may not have any relationship to the epidemiology, right? So, you know, where some zip codes or counties might cross over between two different populations that dont have a lot of contact. And so those problems as well, which I think dealing with communicating those issues was a constant challenge. And then I think you guys got lucky because Justin seems to understand what a scenario is versus a forecast versus, you know, a prediction. Whereas we got yelled at by the governors office because we, even though a model which showed when the peak would be the peak was too high, so they were, they were upset, how should we ever trust you again? But again, like that was, you know, 68 weeks out, you know, the models growing up, you know, its, its sort of like dealing with people that dont understand that difference between sort of a prediction versus a scenario versus the forecast, those sorts of things can be quite complicated. And if you dont have those connections built up on beforehand or you dont have somebody who you can work with directly, you can understand that that makes it quite difficult to be in this space and, and be useful in this space."
18,spk_5,37.877,39.0335,"I think any to your point, no one can make borders, but I think you need to get a recipient on the other side who cares about it too. And, and I think they said it, we were one of the lucky states that our state uh leadership and, and this just in another to take this into consideration, many other states were not that I think at the at least case you probably could present it in other states, they are downright barred from producing models, right? So I think it was a happy influence of we could do the modeling, but we had an audience that was willing to listen. And even with the caveat stated, they are willing to take it in the right spirit. They did not force us to keep saying, you know, forecast whats gonna happen otherwise your model is no birthday. So I, I would thank them as well in class mostly. So this is not to be the case, we really want sometimes to know things that are not within the purview of the modern to talk. Theyre willing to, you know, take the answer that, you know, I dont think we can do it. You get to say something about that."
19,spk_1,39.068666666666665,40.282983333333334,"I think the other big challenge was was how to align, what the models, which I think youre speaking to, how to align with the models could do and what the models could, could evaluate with the policy options that were available at the state level or the county level or the hospital level. So we were asked at some point to look at modeling the impact of closing schools, like what would be that impact or modeling the impact of closing restaurants. And, and again, those have significant economic consequences and, and significant implications. And were doing the best we can to retrofit the models to look at these types of specific events which, you know, may or may not have been originally built into some of the models. Um And so those types of activities can be I think fruitful but also difficult and I think were sort of looking forward, I think some of those things need to be thought through and better able to be communicated so that when, if there is something that does come along, youre able to say, well, here are the potential policy options weve thought through what we could possibly do. Heres what the potential implications of those are from an epidemiological perspective. And then, you know, you can layer on other aspects like  economics and, and other things on top
 of that"
20,spk_0,40.31581666666667,41.82431666666667,"thanks to Dave Higden for launching this question because I think its covered a lot of the topics that we wanted to hit on in terms of learning lessons from the past. Because challenges in communication in general, like communicating across different audience is difficult and especially at times of high uncertainty like this and with data limitations. And also we are talking very different languages and to do this with carrying the plus forward, like models can say one thing based on the data three months later, the data changes. And so the models need to adapt. So such communication needs to be in sync with what the data is rather than just sticking to your guns. What you said one year back if new data comes in and variants have been a very good example of that fully vaccinated status and then boosters were becoming necessary when Han came in. How do you convince the entire set of population who has gotten fully vaccinated and thought it was over to go out there and get another dose? So I think youve highlighted a lot of these. So maybe in the remaining time, we can go to the forward looking parts. So one of the questions we had was based on all the lessons you have learned and obstacles you have faced. How should teams, partnerships and consortiums and you can call it anything but how should they be set up to better handle future pandemic response? And you can take it from like within academics or like academic industry or academic industry and government response or even citizen science. So you can think of it in any ways like, but lee do you want to get started? And then others can chime in?"
21,spk_3,41.8475,41.99848333333333,I actually dont have a good answer to this. I think its like a very lofty goal. I would love to hear what other panelists are thinking.
22,spk_2,42.036316666666664,43.917566666666666,"I am one of the directors in Wappingers Central School District. You know, I Im very excited that the redeemed Department of Health has, has set up this foresight and analytics unit within the Office of Emergency Preparedness. And the goal I think with that is is to maintain these types of Cor Scor MS, these types of relationships that we built up during the pandemic, particularly with the U VA team and with the meta that the forecasting meta forecasting platform and really to tie them to policy decisions. Like we discussed, one of the things that I think we need is to have structures in place data governance structures. A lot of it is, you know, some of the technical challenges we can get enough scientists and engineers on it. Uh they can solve a problem, a lot of its governance issue. A lot of it is coordinations as I call them getting everyone on the same page and and agreeing to do certain things. So having those a process in place for data sharing, whether its continuous or just something that you can ramp up quickly based on certain thresholds or certain needs. I think it is essential. So having those tools in place, having people who are familiar with the data sets to begin with. So I think having a team able to work with the data from the get go is very important and having a pipeline of students, I Im a very big fan of having applied research units, got like your team uh like bio complexity and student, having students have applied a portion of their, you know, whether its an internship or just a uh a practicum working with a public health are in the field somehow. Uh and getting an understanding of, of how things work in a practical and an applied setting where I think its very different than in an academic setting when you, when you tend to have, you know, at that point, cleaner data sets and cleaner questions and cleaner uh assignments. So having all those systems in place, I think it is very important and uh hopefully we can build that going forward."
23,spk_1,43.93565,47.51283333333333,"I think that the efforts have to be at different levels and, and I think theres some thing that is going on, right? So like the CDC and HHS are pushing this forecasting center and that whatever theyre calling it. But that, that is like an actual funded thing where theres going to be constant funding for that, which I think is going to be good at, at an overall level its gonna push a lot of efforts in, in that direction, in terms of building some of this capacity, having it built up. But I think Center for Forecasting Analytics. Thank you, you know, but again, you know, like thats going to be the this question of scale and utility, right? Those numbers, if youre telling Virginia that the peak of the epidemic is gonna be in January, but it actually is gonna peak in Virginia in December. Thats important information that might not come through. Well. And so I think that its important for this national stuff, but I think some of it has to be more at the local level and building these local partnerships. So that as you said, that data is messy, but also the the process of science is messy, right? And so the process of building these models is messy and I part of the thing that needs to be thought about is that whatever the next pandemic is, its not gonna be exactly like this one. And so thinking through what could be the additional challenges that might be needed and what additional data streams might be needed at some point. It is something that I think is what we need to be able to work towards. And then I think the Real World II, I spent a lot of time, my time looking at E hr data and if you want to talk about messi that, thats messy, right? And its very gated and very localized and, and even in like Maryland, where weve got this highly connected system, you can get sort of some access at a clinical level to stuff across the region. Its really hard to get that data at a clinical level or communicated across the multiple places. And Im not trying to say we should knock all those barriers down because theyre certainly important. But its a question of how to deal with those privacy issues and, and H A issues in a very similar way that we have to deal with the mobile phone stuff, right? Its like how do you use this data which can be highly useful in this context but have significant privacy concerns in other arenas. And how do you put that those streams together and start using that in a way that can be actionable i in a way that can influence policy and policy can influence it back. And I think that that has to start at the national level like it is, but I think you have to build these things at the local level as well so that theres local buy in. And, you know, I I think one of the things we saw was that each state had a different team that they were working with and those teams didnt always have high levels of communication. So Ive spoken with Brian several times about different parts of it, but we didnt like look at details of our model and compare that and drive how the differences might affect things and, and I, I dont think thats because we didnt want to or wouldnt have liked to, you know, it was time, like we always just wasnt time to do all of that stuff and provide those things. And so were having some of that stuff built up in terms of like communication across teams as well as communication at the local level would be of high utility. The hard part is, is how to marshal that I think now and in the next couple of years as the emergency ends and and peoples are working 60 80 90 hours a week and they arent focused on. This is the only problem and some new emergency shows up. How do we continue to build that capacity and keep those lines open while dealing with whatever the newest thing is?"
24,spk_0,47.54031666666667,48.318333333333335,"Yeah, I think you bring up a very important point of data stewards in some sense, different entities, the data sites in different locations. I think again, like mother and others can attest to this fact for when we were trying to do like campus level modeling, there are different aspects of the campus that we would like to capture and there are units that are housing those data, but they are say inside the library or some other unit like that. Thats not very evident like when we start looking for it. And I think Lee maybe you have some insights on on the industry front since youve worked with a lot of partners and they have a I I dont know, like I in some sense, they are used to monetizing the data or collecting data on more passive scale. So maybe you have some thoughts on how such practices can be brought in in terms of data stewards and being able to interlink them as and when needed."
25,spk_3,48.36098333333333,49.76148333333333,"Yeah. In the data privacy community, actually, theres been a lot of discussion and even research into this direction, how to monetize or basically making data into a market, right? Data essentially is the value and instead of a binary decision for privacy protection, we dont share the data or with some kind of data privacy solutions essentially just giving a balance between the privacy protection and the utility and the value of the data. But another way kind of a so the way is to think of the data as a value as a monetized value, you can actually trade the data, you can either trade the raw data or you can trade the core results or you can trade the machine learning model that like derived products from the data. So there are actually emerging research that are going on in this area. But in terms of how far is it from realizing it and to get the industry by in that, I guess thats not very clear in the horizon. I mean the the companies probably sell it under the table under the market. But theres no, I guess no, its not the infrastructure or mechanism or transparency that are available yet for the public health agencies to go to the company, for example, to say, OK, lets there are certain needs of the data. Is there any way to actually get access to data? So yeah, I think theres still a way to go in order for us to get there. But thats definitely, I think a promising direction."
26,spk_0,49.775166666666664,50.44481666666667,"Yeah, I think that thats come to the forefront how to get the data where it needs to be and be able to translate it into the decision makers needs. So anything that we can build in terms of either infrastructure but also partnerships that theres a human infrastructure to be built out, theres a compute side of it. So anything that we can do in that direction would be very helpful. Id like to thank again, all the panelists for their valuable insights and all the work that theyve done over the past two years and continue to do even as new variants keep showing up and with monkey pox in the news. So Id like to thank all the panelists and all the audience for sticking around this long day and all your questions."
