{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone_code import *\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "from langchain.chains.conversation.memory import  ConversationBufferWindowMemory, ConversationSummaryBufferMemory, ConversationBufferMemory, ConversationSummaryMemory                             \n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Tpken limit: 16,385\n",
    "# https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
    "\n",
    "# PENDING : Move these to a config file\n",
    "INDEX_NAME = 'resonate-meeting-index' #'langchain-retrieval-transcript'\n",
    "PINECONE_VECTOR_DIMENSION = 3072 #1536\n",
    "PINECONE_UPSERT_BATCH_LIMIT = 90\n",
    "PINECONE_TOP_K_RESULTS = 3\n",
    "DELTA = 5\n",
    "CLOUD_PROVIDER = 'aws'\n",
    "REGION = 'us-west-2'\n",
    "METRIC = 'cosine'\n",
    "\n",
    "EMBEDDING = 'OpenAI'\n",
    "EMBEDDING_MODEL = 'text-embedding-3-large' #'text-embedding-ada-002'\n",
    "# \n",
    "\n",
    "NAMESPACE = 'default_namespace'\n",
    "master_json_file = 'master_meeting_details'\n",
    "\n",
    "LLM_MODEL = 'gpt-3.5-turbo' # gpt-3.5-turbo-1106\n",
    "LLM_TEMPERATURE = 0.0\n",
    "CONV_BUFFER_MEMORY_WINDOW = 2\n",
    "LLM_SUMMARY_MAX_TOKEN_LIMIT = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangChain:\n",
    "    def __init__(self):\n",
    "        self.pinecone_obj = PineconeServerless()\n",
    "        self.llm=ChatOpenAI(temperature=LLM_TEMPERATURE, model_name=LLM_MODEL, streaming=False)\n",
    "        #self.llm=ChatCohere(model='command', temperature=0)\n",
    "        self.conversation_bufw = ConversationChain(llm=self.llm, memory=ConversationBufferWindowMemory(k=CONV_BUFFER_MEMORY_WINDOW))\n",
    "        #self.conversation_bufw = ConversationChain(llm=self.llm, memory=ConversationSummaryBufferMemory(llm=self.llm, max_token_limit=LLM_SUMMARY_MAX_TOKEN_LIMIT))\n",
    "        #self.conversation_bufw = ConversationChain(llm=self.llm, memory=ConversationSummaryMemory(llm=self.llm))\n",
    "        self.df = pd.DataFrame(columns=['Query', 'LLM Input', 'History', \n",
    "                                        'LLM Response', 'Tokens Used',\n",
    "                                        'Prompt Tokens','Completion Tokens', \n",
    "                                        'Total Cost (USD)'])\n",
    "\n",
    "    def prompt(self, query, context):\n",
    "        system_template = SystemMessagePromptTemplate.from_template(\n",
    "            'You are a helpful assistant.'\n",
    "            'You are provided with a context below. You are expected to answer the user query based on the context below.'\n",
    "            'The context provided is a part of transcript of a meeting, in the format:'\n",
    "            'Conversations in meeting: <meeting_title>'\n",
    "            'Start Time - Speaker: Text \\n'\n",
    "\n",
    "            'You will respond using the context below only. If you cannot find an answer from the below context, you can ask for more information.'\n",
    "            'You answers should be concise and relevant to the context.'\n",
    "            'You can mention the meeting_title in your response if you want to refer to the meeting.'\n",
    "            'You are not allowed to talk about anything else other than the context below.'\n",
    "            'You cannot use any external information other than the context below.'\n",
    "            'No need to greet or say goodbye. Just answer the user query based on the context below.'\n",
    "            'You can also skip mentioning phrases such as : Based on the context provided. Instead simply answer the user query based on the context below.\\n\\n'\n",
    "            'Context:\\n'\n",
    "            '{context}'\n",
    "        )\n",
    "        # system_template = SystemMessagePromptTemplate.from_template(\n",
    "        #     'You are a helpful assistant.'\n",
    "        #     'You will answer the user query based on the context below.'\n",
    "        #     'You are also provided with the chat history of the user query and the response. You can use this information to answer the user query as well'\n",
    "        #     'Context: \\n'\n",
    "        #     '{context}'\n",
    "        # )\n",
    "\n",
    "        human_template = HumanMessagePromptTemplate.from_template(' \\nUser Query: {input}')\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_template, human_template])\n",
    "        \n",
    "        chat_prompt_value = chat_prompt.format_prompt(\n",
    "            context = context,\n",
    "            input = query\n",
    "        )\n",
    "        #print(chat_prompt_value)\n",
    "        return chat_prompt_value.to_messages()\n",
    "\n",
    "\n",
    "    def query_chatbot(self, query, context):\n",
    "        self.messages = self.prompt(query, context)\n",
    "        #resp = self.conversation_bufw(self.messages)\n",
    "        resp, callback = self.count_tokens(self.conversation_bufw, self.messages)\n",
    "        # append resp, callback to df\n",
    "        #print(\"Resp: \", resp)\n",
    "        #print(\"Callback: \", callback)\n",
    "\n",
    "    \n",
    "        self.df = pd.concat([self.df, pd.DataFrame({\n",
    "            'Query': query,\n",
    "            'LLM Input': str(resp['input']), \n",
    "            'History': str(resp['history']), \n",
    "            'LLM Response': str(resp['response']), \n",
    "            'Tokens Used': callback['Tokens Used'],\n",
    "            'Prompt Tokens': callback['Prompt Tokens'],\n",
    "            'Completion Tokens': callback['Completion Tokens'],\n",
    "            'Total Cost (USD)': str(callback['Total Cost (USD)']).replace('$', '')\n",
    "             }, \n",
    "            index = [0])], ignore_index=True)\n",
    "\n",
    "        print(\"Tokens Used: \", callback['Tokens Used'])\n",
    "        return resp\n",
    "        #return resp['response']\n",
    "    \n",
    "    def parse_conversations(self, conversations) -> str:\n",
    "        data = []\n",
    "        for cluster_id, cluster_df in conversations.items():\n",
    "            with open(f'../../bin/data/default_namespace/{cluster_id}.json') as f:\n",
    "                meeting_data = json.load(f)\n",
    "                meeting_title = meeting_data['meeting_title']\n",
    "                data.append(f\"Conversations in meeting '{meeting_title}':\")\n",
    "                for i, row in cluster_df.iterrows():\n",
    "                    data.append(f\"{row['start_time']} - {row['speaker']}: {row['text']}\")\n",
    "                data.append(\"\\n\\n\")\n",
    "        data = '\\n'.join(data)\n",
    "        return data\n",
    "\n",
    "    def clear_conversational_memory(self):\n",
    "        self.conversation_bufw.memory.clear()\n",
    "\n",
    "    def chat(self, query, in_filter: list[str]=[], complete_db_flag:bool = True):\n",
    "        if 'summary' in query:\n",
    "            pass\n",
    "        self.pinecone_obj.query_pinecone(query, in_filter, complete_db_flag)\n",
    "        conversation = self.pinecone_obj.query_delta_conversations()\n",
    "        context = self.parse_conversations(conversation)\n",
    "        #print(context)\n",
    "        try:\n",
    "            response = self.query_chatbot(query, context)\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "            response = \"Oops! you have exhausted the token limit, clearing the conversational memory. Please try again.\"   \n",
    "            self.clear_conversational_memory() \n",
    "        return response\n",
    "    \n",
    "    def count_tokens(self, chain, query):\n",
    "        with get_openai_callback() as callback:\n",
    "            response = chain(query)\n",
    "            #print(f'Call Back:  {callback}')\n",
    "            print(f'Spent a total of {callback.total_tokens} tokens')\n",
    "            callback = str(callback)\n",
    "            lines = callback.split('\\n')\n",
    "            data = {}\n",
    "            for line in lines:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) == 2:\n",
    "                    key = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    data[key] = str(value)\n",
    "            #print(data)       \n",
    "            return response, data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = LangChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"How much is the compensation for the job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"Whats the minimum age that you need to be in order to do shadowing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"Who was talking about electives?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"Why were the volunteer programs canceled?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"The minimum age to do what is 17?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"Who will be sending the emails?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"From which school is the director from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"When are the sessions scheduled to take place each month?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.chat(\"Who is the director of Human Resources at Premier Medical Group?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna = pd.read_csv('qna.csv')\n",
    "obj = LangChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Fetch window:  ['19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29']\n",
      "Fetch window:  ['1', '2', '3', '4', '5', '6', '7']\n",
      "Fetch window:  ['41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sbhuv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 5160 tokens\n",
      "Tokens Used:  5160\n",
      "1\n",
      "Fetch window:  ['34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44']\n",
      "Fetch window:  ['46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56']\n",
      "Fetch window:  ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50']\n",
      "Spent a total of 9311 tokens\n",
      "Tokens Used:  9311\n",
      "2\n",
      "Fetch window:  ['56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66']\n",
      "Fetch window:  ['53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63']\n",
      "Fetch window:  ['51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61']\n",
      "Spent a total of 11985 tokens\n",
      "Tokens Used:  11985\n",
      "3\n",
      "Fetch window:  ['35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45']\n",
      "Fetch window:  ['34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44']\n",
      "Fetch window:  ['76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86']\n",
      "Spent a total of 9058 tokens\n",
      "Tokens Used:  9058\n",
      "4\n",
      "Fetch window:  ['68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78']\n",
      "Fetch window:  ['70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Fetch window:  ['72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82']\n",
      "Spent a total of 6061 tokens\n",
      "Tokens Used:  6061\n",
      "5\n",
      "Fetch window:  ['29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39']\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Fetch window:  ['1', '2', '3', '4', '5', '6']\n",
      "Spent a total of 7664 tokens\n",
      "Tokens Used:  7664\n",
      "6\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Fetch window:  ['12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']\n",
      "Fetch window:  ['22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\n",
      "Spent a total of 8559 tokens\n",
      "Tokens Used:  8559\n",
      "7\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Fetch window:  ['60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70']\n",
      "Fetch window:  ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Spent a total of 12400 tokens\n",
      "Tokens Used:  12400\n",
      "8\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Fetch window:  ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Fetch window:  ['22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\n",
      "Spent a total of 13267 tokens\n",
      "Tokens Used:  13267\n",
      "9\n",
      "Fetch window:  ['12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']\n",
      "Fetch window:  ['37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47']\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Spent a total of 13127 tokens\n",
      "Tokens Used:  13127\n",
      "10\n",
      "Fetch window:  ['41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51']\n",
      "Fetch window:  ['44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54']\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Spent a total of 10640 tokens\n",
      "Tokens Used:  10640\n",
      "11\n",
      "Fetch window:  ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50']\n",
      "Fetch window:  ['41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51']\n",
      "Fetch window:  ['34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44']\n",
      "Spent a total of 7861 tokens\n",
      "Tokens Used:  7861\n",
      "12\n",
      "Fetch window:  ['46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56']\n",
      "Fetch window:  ['47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57']\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Spent a total of 9057 tokens\n",
      "Tokens Used:  9057\n",
      "13\n",
      "Fetch window:  ['68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78']\n",
      "Fetch window:  ['70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Spent a total of 8890 tokens\n",
      "Tokens Used:  8890\n",
      "14\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Fetch window:  ['41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51']\n",
      "Fetch window:  ['47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57']\n",
      "Spent a total of 10784 tokens\n",
      "Tokens Used:  10784\n",
      "15\n",
      "Fetch window:  ['51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61']\n",
      "Fetch window:  ['32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42']\n",
      "Fetch window:  ['1', '2', '3', '4', '5', '6', '7']\n",
      "Spent a total of 13122 tokens\n",
      "Tokens Used:  13122\n",
      "16\n",
      "Fetch window:  ['51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61']\n",
      "Fetch window:  ['1', '2', '3', '4', '5', '6', '7']\n",
      "Fetch window:  ['12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']\n",
      "Error: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 16716 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Oops! you have exhausted the token limit, clearing the conversational memory. Please try again.\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(i)\n",
    "    query = qna['questions'][i]\n",
    "    response = obj.chat(query)\n",
    "    if response == 'Oops! you have exhausted the token limit, clearing the conversational memory. Please try again.':\n",
    "        print(response)\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df.to_csv(f'ConversationBufferWindowMemory_{CONV_BUFFER_MEMORY_WINDOW}tokens_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df.to_excel(f'ConversationBufferWindowMemory_{CONV_BUFFER_MEMORY_WINDOW}K_.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df.to_json(f'ConversationBufferWindowMemory_{CONV_BUFFER_MEMORY_WINDOW}K_.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>LLM Input</th>\n",
       "      <th>History</th>\n",
       "      <th>LLM Response</th>\n",
       "      <th>Tokens Used</th>\n",
       "      <th>Prompt Tokens</th>\n",
       "      <th>Completion Tokens</th>\n",
       "      <th>Total Cost (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much is the compensation for the job?</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td></td>\n",
       "      <td>The compensation for the job is about $32,000 ...</td>\n",
       "      <td>5160</td>\n",
       "      <td>5137</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0077515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whats the minimum age that you need to be in o...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>The minimum age to do shadowing is typically a...</td>\n",
       "      <td>9311</td>\n",
       "      <td>9296</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was talking about electives?</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Miss Ingham was talking about electives.</td>\n",
       "      <td>11985</td>\n",
       "      <td>11975</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0179825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The minimum age to do what is 17?</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>The minimum age to do shadowing is 17 years old.</td>\n",
       "      <td>9058</td>\n",
       "      <td>9045</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0135935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why were the volunteer programs canceled?</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>The volunteer programs were canceled because o...</td>\n",
       "      <td>6061</td>\n",
       "      <td>6050</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who is the director of Human Resources at Prem...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>The director of Human Resources at Premier Med...</td>\n",
       "      <td>7664</td>\n",
       "      <td>7649</td>\n",
       "      <td>15</td>\n",
       "      <td>0.011503500000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What types of healthcare positions does Premie...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Premier Medical Group offers various types of ...</td>\n",
       "      <td>8559</td>\n",
       "      <td>8523</td>\n",
       "      <td>36</td>\n",
       "      <td>0.012856499999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are some reasons someone might want to pu...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Some reasons someone might want to pursue a ca...</td>\n",
       "      <td>12400</td>\n",
       "      <td>12328</td>\n",
       "      <td>72</td>\n",
       "      <td>0.018635999999999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are some benefits of working in the healt...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Some benefits of working in the healthcare fie...</td>\n",
       "      <td>13267</td>\n",
       "      <td>13206</td>\n",
       "      <td>61</td>\n",
       "      <td>0.019931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are some examples of technical healthcare...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Some examples of technical healthcare jobs inc...</td>\n",
       "      <td>13127</td>\n",
       "      <td>13078</td>\n",
       "      <td>49</td>\n",
       "      <td>0.019715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What education is required for a physician ass...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>The education required for a physician assista...</td>\n",
       "      <td>10640</td>\n",
       "      <td>10627</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0159665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is shadowing in the context of healthcare?</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Shadowing in the context of healthcare involve...</td>\n",
       "      <td>7861</td>\n",
       "      <td>7805</td>\n",
       "      <td>56</td>\n",
       "      <td>0.011819499999999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How can students find opportunities to shadow ...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Students can find opportunities to shadow heal...</td>\n",
       "      <td>9057</td>\n",
       "      <td>8999</td>\n",
       "      <td>58</td>\n",
       "      <td>0.013614500000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What are some volunteer opportunities in healt...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Some volunteer opportunities in healthcare inc...</td>\n",
       "      <td>8890</td>\n",
       "      <td>8836</td>\n",
       "      <td>54</td>\n",
       "      <td>0.013362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What resources can students use to research he...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Students can use resources such as the US News...</td>\n",
       "      <td>10784</td>\n",
       "      <td>10728</td>\n",
       "      <td>56</td>\n",
       "      <td>0.016204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is the role of Dutchess Community College...</td>\n",
       "      <td>[SystemMessage(content=\"You are a helpful assi...</td>\n",
       "      <td>Human: [{'content': \"You are a helpful assista...</td>\n",
       "      <td>Dutchess Community College plays a significant...</td>\n",
       "      <td>13122</td>\n",
       "      <td>12997</td>\n",
       "      <td>125</td>\n",
       "      <td>0.0197455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Query  \\\n",
       "0           How much is the compensation for the job?   \n",
       "1   Whats the minimum age that you need to be in o...   \n",
       "2                    Who was talking about electives?   \n",
       "3                   The minimum age to do what is 17?   \n",
       "4           Why were the volunteer programs canceled?   \n",
       "5   Who is the director of Human Resources at Prem...   \n",
       "6   What types of healthcare positions does Premie...   \n",
       "7   What are some reasons someone might want to pu...   \n",
       "8   What are some benefits of working in the healt...   \n",
       "9   What are some examples of technical healthcare...   \n",
       "10  What education is required for a physician ass...   \n",
       "11    What is shadowing in the context of healthcare?   \n",
       "12  How can students find opportunities to shadow ...   \n",
       "13  What are some volunteer opportunities in healt...   \n",
       "14  What resources can students use to research he...   \n",
       "15  What is the role of Dutchess Community College...   \n",
       "\n",
       "                                            LLM Input  \\\n",
       "0   [SystemMessage(content=\"You are a helpful assi...   \n",
       "1   [SystemMessage(content=\"You are a helpful assi...   \n",
       "2   [SystemMessage(content=\"You are a helpful assi...   \n",
       "3   [SystemMessage(content=\"You are a helpful assi...   \n",
       "4   [SystemMessage(content=\"You are a helpful assi...   \n",
       "5   [SystemMessage(content=\"You are a helpful assi...   \n",
       "6   [SystemMessage(content=\"You are a helpful assi...   \n",
       "7   [SystemMessage(content=\"You are a helpful assi...   \n",
       "8   [SystemMessage(content=\"You are a helpful assi...   \n",
       "9   [SystemMessage(content=\"You are a helpful assi...   \n",
       "10  [SystemMessage(content=\"You are a helpful assi...   \n",
       "11  [SystemMessage(content=\"You are a helpful assi...   \n",
       "12  [SystemMessage(content=\"You are a helpful assi...   \n",
       "13  [SystemMessage(content=\"You are a helpful assi...   \n",
       "14  [SystemMessage(content=\"You are a helpful assi...   \n",
       "15  [SystemMessage(content=\"You are a helpful assi...   \n",
       "\n",
       "                                              History  \\\n",
       "0                                                       \n",
       "1   Human: [{'content': \"You are a helpful assista...   \n",
       "2   Human: [{'content': \"You are a helpful assista...   \n",
       "3   Human: [{'content': \"You are a helpful assista...   \n",
       "4   Human: [{'content': \"You are a helpful assista...   \n",
       "5   Human: [{'content': \"You are a helpful assista...   \n",
       "6   Human: [{'content': \"You are a helpful assista...   \n",
       "7   Human: [{'content': \"You are a helpful assista...   \n",
       "8   Human: [{'content': \"You are a helpful assista...   \n",
       "9   Human: [{'content': \"You are a helpful assista...   \n",
       "10  Human: [{'content': \"You are a helpful assista...   \n",
       "11  Human: [{'content': \"You are a helpful assista...   \n",
       "12  Human: [{'content': \"You are a helpful assista...   \n",
       "13  Human: [{'content': \"You are a helpful assista...   \n",
       "14  Human: [{'content': \"You are a helpful assista...   \n",
       "15  Human: [{'content': \"You are a helpful assista...   \n",
       "\n",
       "                                         LLM Response Tokens Used  \\\n",
       "0   The compensation for the job is about $32,000 ...        5160   \n",
       "1   The minimum age to do shadowing is typically a...        9311   \n",
       "2            Miss Ingham was talking about electives.       11985   \n",
       "3    The minimum age to do shadowing is 17 years old.        9058   \n",
       "4   The volunteer programs were canceled because o...        6061   \n",
       "5   The director of Human Resources at Premier Med...        7664   \n",
       "6   Premier Medical Group offers various types of ...        8559   \n",
       "7   Some reasons someone might want to pursue a ca...       12400   \n",
       "8   Some benefits of working in the healthcare fie...       13267   \n",
       "9   Some examples of technical healthcare jobs inc...       13127   \n",
       "10  The education required for a physician assista...       10640   \n",
       "11  Shadowing in the context of healthcare involve...        7861   \n",
       "12  Students can find opportunities to shadow heal...        9057   \n",
       "13  Some volunteer opportunities in healthcare inc...        8890   \n",
       "14  Students can use resources such as the US News...       10784   \n",
       "15  Dutchess Community College plays a significant...       13122   \n",
       "\n",
       "   Prompt Tokens Completion Tokens      Total Cost (USD)  \n",
       "0           5137                23             0.0077515  \n",
       "1           9296                15              0.013974  \n",
       "2          11975                10             0.0179825  \n",
       "3           9045                13             0.0135935  \n",
       "4           6050                11              0.009097  \n",
       "5           7649                15  0.011503500000000002  \n",
       "6           8523                36  0.012856499999999998  \n",
       "7          12328                72  0.018635999999999996  \n",
       "8          13206                61              0.019931  \n",
       "9          13078                49              0.019715  \n",
       "10         10627                13             0.0159665  \n",
       "11          7805                56  0.011819499999999998  \n",
       "12          8999                58  0.013614500000000002  \n",
       "13          8836                54              0.013362  \n",
       "14         10728                56              0.016204  \n",
       "15         12997               125             0.0197455  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
